{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71fae7e-a4c4-4950-8c16-4a74a1e69482",
   "metadata": {
    "id": "c71fae7e-a4c4-4950-8c16-4a74a1e69482"
   },
   "source": [
    "# Pipeline for High-z Radio Galaxies 05: AGN confusion matrix analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a7301-9b3d-4ad9-9659-b68cad4014c5",
   "metadata": {
    "id": "714a7301-9b3d-4ad9-9659-b68cad4014c5"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6dd12-650e-4ab6-bae7-0268f78e7fea",
   "metadata": {
    "id": "dea6dd12-650e-4ab6-bae7-0268f78e7fea"
   },
   "source": [
    "We want to understand how sources get to be in any quadrant of the confusion  \n",
    "matrix for the prediction of AGN detection.  \n",
    "In order to do that, we analyse the distribution of properties of the sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0aec8-0112-4728-a8fe-f99cdf05a33b",
   "metadata": {
    "id": "00a0aec8-0112-4728-a8fe-f99cdf05a33b"
   },
   "source": [
    "Training data is from HETDEX Spring Field.  \n",
    "Deployment data is from Stripe 82 Field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1161a2b6-ef8d-429d-8dea-40f0de36e393",
   "metadata": {
    "id": "1161a2b6-ef8d-429d-8dea-40f0de36e393"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as mpe\n",
    "import mpl_scatter_density\n",
    "from astropy.visualization import LogStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve, RocCurveDisplay, matthews_corrcoef\n",
    "from sklearn.calibration import calibration_curve\n",
    "import sklearn.pipeline\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "from pycaret import classification as pyc\n",
    "# from pycaret import regression as pyr\n",
    "import pandas as pd\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c08229-3870-441e-892c-08e3e71aaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647d74a-8d80-4d24-a2f4-023184fa27ac",
   "metadata": {
    "id": "9647d74a-8d80-4d24-a2f4-023184fa27ac"
   },
   "source": [
    "Create class to normalize asymmetric colorscales  \n",
    "(from [http://chris35wills.github.io/matplotlib_diverging_colorbar/](http://chris35wills.github.io/matplotlib_diverging_colorbar/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652a8557-e595-4861-af72-5d3220fb7620",
   "metadata": {
    "id": "652a8557-e595-4861-af72-5d3220fb7620",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MidpointNormalize(mcolors.Normalize):\n",
    "    \"\"\"\n",
    "    Normalise the colorbar so that diverging bars work there way either side from a prescribed midpoint value)\n",
    "\n",
    "    e.g. im=ax1.imshow(array, norm=MidpointNormalize(midpoint=0.,vmin=-100, vmax=100))\n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mcolors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y), np.isnan(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc24aa0-581a-4c39-bc90-b18f85385e78",
   "metadata": {
    "id": "0bc24aa0-581a-4c39-bc90-b18f85385e78"
   },
   "source": [
    "For future plots, we can configure their aspect too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc05a86c-85e4-46e7-9b7f-f8ac4abd4ff2",
   "metadata": {
    "id": "cc05a86c-85e4-46e7-9b7f-f8ac4abd4ff2",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap           = cm.get_cmap('inferno')\n",
    "cmap_alt       = cm.get_cmap('Dark2')\n",
    "cmap_alt_2     = cm.get_cmap('Greys_r')  # Shades of grey\n",
    "cmap_alt_3     = cm.get_cmap('coolwarm')  # blue to red\n",
    "dark_color     = cmap(0.4)  # RGBA color code\n",
    "light_color    = cmap(0.6)  # RGBA color code\n",
    "colors         = [cmap(0.15), cmap(0.30), cmap(0.45), cmap(0.60), cmap(0.75), cmap(0.90)]\n",
    "colors_3       = [cmap(0.25), cmap(0.50), cmap(0.75)]\n",
    "colors_3_alt   = [cmap_alt(0.25), cmap_alt(0.50), cmap_alt(0.75)]\n",
    "colors_3_alt_2 = [cmap_alt_2(0.25), cmap_alt_2(0.50), cmap_alt_2(0.75)]\n",
    "colors_8       = [cmap(0.12), cmap(0.24), cmap(0.35), cmap(0.48), cmap(0.6), cmap(0.72), cmap(0.84), cmap(0.96)]\n",
    "colors_8_alt   = [cmap_alt(0.12), cmap_alt(0.24), cmap_alt(0.35), cmap_alt(0.48), cmap_alt(0.6), cmap_alt(0.72),\\\n",
    "                  cmap_alt(0.84), cmap_alt(0.96)]\n",
    "colors_8_alt_2 = [cmap_alt_2(0.06), cmap_alt_2(0.18), cmap_alt_2(0.29), cmap_alt_2(0.42), cmap_alt_2(0.54),\\\n",
    "                  cmap_alt_2(0.66), cmap_alt_2(0.78), cmap_alt_2(0.90)]\n",
    "colors_8_alt_3 = [cmap_alt_3(0.06), cmap_alt_3(0.18), cmap_alt_3(0.29), cmap_alt_3(0.42), cmap_alt_3(0.54),\\\n",
    "                  cmap_alt_3(0.66), cmap_alt_3(0.78), cmap_alt_3(0.90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b5bb0d-e1c0-415d-b7a8-3237c86e6c7b",
   "metadata": {
    "id": "f7b5bb0d-e1c0-415d-b7a8-3237c86e6c7b",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe1            = [mpe.Stroke(linewidth=5.0, foreground='black'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]\n",
    "pe2            = [mpe.Stroke(linewidth=3.0, foreground='white'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]\n",
    "\n",
    "alp_str        = r'$\\alpha$'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf1d05-0bd7-4cbe-a480-5bd658bc008c",
   "metadata": {
    "id": "aacf1d05-0bd7-4cbe-a480-5bd658bc008c"
   },
   "source": [
    "Methdods for PyCaret and saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b96d4e-620f-4572-8a2c-eb5faa7238e5",
   "metadata": {
    "id": "86db6e67-85aa-4cd6-a3dc-bfe638bc69bb",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_final_column_names(pycaret_pipeline, sample_df):\n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        for (name, method) in pycaret_pipeline.named_steps.items():\n",
    "            if method != 'passthrough' and name != 'trained_model':\n",
    "                print(f'Running {name}')\n",
    "                sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()\n",
    "    else:\n",
    "        for (name, method) in pyc.get_config('prep_pipe').named_steps.items():\n",
    "            if method != 'passthrough' and name != 'trained_model':\n",
    "                print(f'Running {name}')\n",
    "                sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee49c70-46cb-41f2-aed1-5c111a89d913",
   "metadata": {
    "id": "715acda9-475d-4c9c-8e99-4921da2e1152",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_importances_df(pycaret_pipeline, sample_df, n = 10):\n",
    "    \n",
    "    final_cols = get_final_column_names(pycaret_pipeline, sample_df)\n",
    "    \n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        try:\n",
    "            variables = pycaret_pipeline[\"trained_model\"].feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline[\"trained_model\"].estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            variables = pycaret_pipeline.feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline.estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mat(confusion_matrix, title, axin, display_labels=['Non true', 'True'], cmap='cet_dimgray_r', show_clb=False, log_stretch=False):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,\n",
    "                              display_labels=display_labels)\n",
    "\n",
    "    min_val_colour = np.nanmin(confusion_matrix)\n",
    "    max_val_colour = np.nanmin(confusion_matrix)\n",
    "    \n",
    "    if log_stretch:\n",
    "        norm = ImageNormalize(stretch=LogStretch())\n",
    "    if not log_stretch:\n",
    "        norm = ImageNormalize()\n",
    "\n",
    "    # NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
    "    disp_b = disp.plot(include_values=True, cmap=cm.get_cmap(cmap),\\\n",
    "             ax=axin, xticks_rotation='horizontal')\n",
    "\n",
    "    for text_val in disp_b.text_.flatten():\n",
    "        text_val.set_fontsize(30)\n",
    "    clb = plt.gca().images[-1].colorbar\n",
    "    clb.ax.tick_params(labelsize=14)\n",
    "    clb.ax.ticklabel_format(style='sci', scilimits=(0, 0))\n",
    "    clb.outline.set_linewidth(2.5)\n",
    "    clb.ax.set_ylabel('Elements in bin', size=14)\n",
    "    if not show_clb:\n",
    "        clb.remove()\n",
    "\n",
    "    # disp_b.im_.set_clim(1e2, 3e3)\n",
    "    disp_b.im_.norm = norm\n",
    "\n",
    "    axin.xaxis.get_label().set_fontsize(16)\n",
    "    axin.yaxis.get_label().set_fontsize(16)\n",
    "\n",
    "    axin.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    axin.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC_from_CM(cm_array):  # Matthews correlation coefficient\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a217d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACC_from_CM(cm_array):  # Accuracy\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01daba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_from_CM(cm_array):  # F-1 score\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ba666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_from_CM(cm_array):  # Recall\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    Recall = TP / (TP + FN)\n",
    "    return Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222df68-1b98-436b-af43-d9f38d015ba6",
   "metadata": {
    "id": "8222df68-1b98-436b-af43-d9f38d015ba6"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce5669-172d-4ed4-b6fe-5fff8afc7df5",
   "metadata": {
    "id": "e2ce5669-172d-4ed4-b6fe-5fff8afc7df5"
   },
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0619b32-391c-4f18-8284-d1fabf6a800c",
   "metadata": {
    "id": "b0619b32-391c-4f18-8284-d1fabf6a800c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_path    = '../../Catalogs/'  # relative path to the same directory\n",
    "models_path = 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e41fd8-fbc5-4185-b03e-8a57634a05a9",
   "metadata": {
    "id": "c4e41fd8-fbc5-4185-b03e-8a57634a05a9"
   },
   "source": [
    "We import our data using the `pandas` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2f62f66-a612-49f8-83e6-b57cdd21e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_flag  = False\n",
    "save_model_flag = False\n",
    "load_model_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583dbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_dataset    = 'HETDEX'  # 'HETDEX', 'S82', or 'COSMOS'\n",
    "# used_dataset    = 'S82'\n",
    "# used_dataset    = 'COSMOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b65783-eee3-44e5-b164-626f6f15afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_5sigma = True  # use files with 5-sigma magnitude imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7d0421-42f6-4787-9068-fa44b3b52e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqc_version = '7_4d'  # '7_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69bd7ee-7184-46e3-a6cb-1a66cb75d6ae",
   "metadata": {
    "id": "c69bd7ee-7184-46e3-a6cb-1a66cb75d6ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if used_dataset == 'HETDEX':\n",
    "    data_file = f'CatWISE2020_VLASS_LOFAR_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_{mqc_version}_ALLWISE_LOLSS_SDSS_DR16_5sigma_imp.h5'  # 6729647 objects (6.7e6)\n",
    "elif used_dataset == 'S82':\n",
    "    data_file = f'CatWISE2020_S82_VLASS_VLAS82_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_{mqc_version}_ALLWISE_SDSS_DR16_5sigma_imp.h5'  # 369093 objects (3.7e5)\n",
    "else:\n",
    "    data_file = f'CatWISE2020_COSMOS_MILLIQUAS_{mqc_version}_COSMOSVLA3_PS1_GALEX_TGSS_VLASS_XMM_2MASS_ALLWISE_SDSS_DR16_5sigma_imp.h5'  # 72120 objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd751bd-1eb4-4c54-b6fa-418773ac8938",
   "metadata": {
    "id": "2cd751bd-1eb4-4c54-b6fa-418773ac8938"
   },
   "source": [
    "First, open the file as astropy Table to modify (and standardise)  \n",
    "the units of fluxes and/or magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a606d-3140-4b8d-8e79-9a145df74f1a",
   "metadata": {
    "id": "d0ce0178-04a7-4113-bbb8-1b70ce220764"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66f66c-4987-4340-bf82-7d8e218033fb",
   "metadata": {
    "id": "6e66f66c-4987-4340-bf82-7d8e218033fb"
   },
   "source": [
    "Create `pandas` DataFrame from `astropy` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2_discard = ['objID', 'RA_ICRS', 'DE_ICRS', 'Name', 'RA_MILLI', 'DEC_MILLI',\\\n",
    "                     'TYPE', 'Z', 'radio_detect', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "                     'Sint_LOFAR', 'Stotal_TGSS', 'FEP', 'TotalFlux_LoLSS'] # , 'mode',\\\n",
    "                     # 'class', 'f_zsp', 'subCl', 'zph', 'e_zph']  # Not needed for training in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "498083f5-b8c6-44aa-8de4-75b1dc899296",
   "metadata": {
    "id": "498083f5-b8c6-44aa-8de4-75b1dc899296",
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_catalog_df = pd.read_hdf(cat_path + data_file, key='df').drop(columns=features_2_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7373cafa-c176-4a4d-b366-4a9b357e7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11296d1a",
   "metadata": {},
   "source": [
    "#### Select only confirmed galaxies and AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08f37a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_size       = len(full_catalog_df)\n",
    "full_catalog_df = full_catalog_df.loc[(full_catalog_df.loc[:, 'is_gal'] == 1) | (full_catalog_df.loc[:, 'is_AGN'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176ab5f7-d85f-4d5c-9ef3-ae7c36f21539",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataset, with 85548 elements,\n",
      "30395 of them are marked as AGN, and 55153 are identified as galaxies.\n"
     ]
    }
   ],
   "source": [
    "n_is_AGN = np.sum(full_catalog_df.loc[:, 'is_AGN'] == 1)\n",
    "n_is_gal = np.sum(full_catalog_df.loc[:, 'is_gal'] == 1)\n",
    "print(f'In this dataset, with {orig_size} elements,\\n' +\\\n",
    "         f'{n_is_AGN} of them are marked as AGN, and {n_is_gal} are identified as galaxies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619390c-a04f-4bd0-9f97-9ca54bc9c764",
   "metadata": {
    "id": "6619390c-a04f-4bd0-9f97-9ca54bc9c764"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27645d12-9370-40d8-aeba-24d4415bb9eb",
   "metadata": {
    "id": "27645d12-9370-40d8-aeba-24d4415bb9eb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u4vi69d_pPbd",
   "metadata": {
    "id": "u4vi69d_pPbd"
   },
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8byjjVU3pOjM",
   "metadata": {
    "id": "8byjjVU3pOjM"
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3765bf6",
   "metadata": {},
   "source": [
    "Create target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb5045-215a-44d0-acf5-438e68f98921",
   "metadata": {},
   "source": [
    "$0$ for galaxies and $1$ for AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a19415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['class'] = full_catalog_df.loc[:, 'is_AGN'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce06574-16aa-49c0-afa8-e623a129dc3a",
   "metadata": {},
   "source": [
    "Remove intermediate targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6723ecb-c503-4f27-9b9b-6d2e5a1b5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = full_catalog_df.drop(columns=['is_AGN', 'is_SDSS_gal', 'is_gal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b19461",
   "metadata": {},
   "source": [
    "#### Add columns with classes as shown by TYPE column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399591b7",
   "metadata": {},
   "source": [
    "MQC v7.4d says:\n",
    "\n",
    "Legend of type/class:  \n",
    "     ``Q = QSO, type-I broad-line core-dominated, 792372 of these.``  \n",
    "     ``A = AGN, type-I Seyferts/host-dominated, 41983 of these.``  \n",
    "     ``B = BL Lac type object, 2744 of these.``  \n",
    "     ``L = lensed quasar extra image, only 66 of these in this optical data.``  \n",
    "     ``K = NLQSO, type-II narrow-line core-dominated, 5798 of these.``  \n",
    "     ``N = NLAGN, type-II Seyferts/host-dominated, 39366 of these.  Includes an``  \n",
    "                ``unquantified residue of legacy NELGs/ELGs/LINERs.``  \n",
    "     ``R = radio association displayed.``  \n",
    "     ``X = X-ray association displayed.``  \n",
    "     ``2 = double radio lobes displayed (declared by data-driven algorithm).``  \n",
    "\n",
    "QSO candidates (type starting with ``R/X/2``)  \n",
    "Fully classified object (type starting with ``Q/A/B/K/N/L``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c842dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MQC_types = ['Q', 'A', 'B', 'K', 'N', 'L', 'R', 'X', '2']\n",
    "for type_val in MQC_types:\n",
    "    full_catalog_df[f'is_{type_val}'] = np.array(full_catalog_df.loc[:, 'TYPE'].str.contains(type_val, regex=False)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703c5a2",
   "metadata": {},
   "source": [
    "### Split data: Test, Train, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8f8310-48c9-44ae-a998-da69fa736919",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of used data\n",
      "----------------------------------------\n",
      "Full Dataset size: (85548, 42)\n",
      "Data for Modeling (Train and Test): (68438, 42)\n",
      "Unseen Data For Validation: (17110, 42)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_test_df, validation_df     = train_test_split(full_catalog_df, test_size=0.2,\\\n",
    "                                   random_state=seed, stratify=full_catalog_df.loc[:, 'class'])\n",
    "# data_train_test_AGN_df = full_catalog_df.sample(frac=0.9, random_state=seed)  # Train + test sets\n",
    "# data_validation_AGN_df = full_catalog_df.drop(data_train_test_AGN_df.index)  # Validation data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_test_df, test_size=0.3,\\\n",
    "                                   random_state=seed, stratify=train_test_df.loc[:, 'class'])\n",
    "\n",
    "train_df                         = pd.concat([X_train, y_train], axis=1)\n",
    "test_df                          = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "print('Shape of used data')\n",
    "print('-' * 50)\n",
    "print(f'Full Dataset size:                  {full_catalog_df.shape}')\n",
    "print(f'Data for Modeling (Train and Test): {train_test_df.shape}')\n",
    "print(f'Training data:                      {train_df.shape}')\n",
    "print(f'Testing data:                       {test_df.shape}')\n",
    "print(f'Unseen Data For Validation:         {validation_df.shape}')\n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70583603",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_filters_df  = pd.DataFrame(data=np.array([[False] * len(full_catalog_df),\\\n",
    "                     [False] * len(full_catalog_df),\\\n",
    "                     [False] * len(full_catalog_df)]).T, columns=['train', 'test', 'validation'])\n",
    "subset_filters_df.loc[test_df.index,       'train']      = True\n",
    "subset_filters_df.loc[train_df.index,      'test']       = True\n",
    "subset_filters_df.loc[validation_df.index, 'validation'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5d457-4601-40bd-9bc3-6576c691d87d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b0e6e",
   "metadata": {},
   "source": [
    "## Load model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGN_model_01 = pyc.load_model(models_path + 'classification_AGN_galaxy_apr_20_2022')  # using only confirmed sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898086d",
   "metadata": {},
   "source": [
    "### AGN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_AGN = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_AGN_all = pyc.predict_model(AGN_model_01, data=full_catalog_df,\\\n",
    "                                        probability_threshold=threshold_AGN,\\\n",
    "                                        raw_score=True, round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_AGN_train = data_pred_AGN_all.loc[train_df.index]\n",
    "data_pred_AGN_test  = data_pred_AGN_all.loc[test_df.index]\n",
    "data_pred_AGN_val   = data_pred_AGN_all.loc[validation_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf0a6e",
   "metadata": {},
   "source": [
    "### Create confusion matrices and scores for all individual TYPEs of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mat_MQC_filts = {}\n",
    "cm_mat_MQC       = {}\n",
    "TN_MQC           = {}\n",
    "FP_MQC           = {}\n",
    "FN_MQC           = {}\n",
    "TP_MQC           = {}\n",
    "MCC_MQC          = {}\n",
    "ACC_MQC          = {}\n",
    "F1_MQC           = {}\n",
    "Recall_MQC       = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2342fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_val in MQC_types:\n",
    "    cm_mat_MQC_filts[type_val] = np.array([[(np.array(data_pred_AGN_all[f'is_{type_val}'] == 0) & np.array(data_pred_AGN_all['Label_AGN'] == 0)),\\\n",
    "                                 (np.array(data_pred_AGN_all[f'is_{type_val}'] == 0) & np.array(data_pred_AGN_all['Label_AGN'] == 1))],\\\n",
    "                                 [(np.array(data_pred_AGN_all[f'is_{type_val}'] == 1) & np.array(data_pred_AGN_all['Label_AGN'] == 0)),\\\n",
    "                                 (np.array(data_pred_AGN_all[f'is_{type_val}'] == 1) & np.array(data_pred_AGN_all['Label_AGN'] == 1))]])\n",
    "    cm_mat_MQC[type_val]       = np.array([[np.sum(cm_mat_MQC_filts[type_val][0, 0]), np.sum(cm_mat_MQC_filts[type_val][0, 1])],\\\n",
    "                                 [np.sum(cm_mat_MQC_filts[type_val][1, 0]), np.sum(cm_mat_MQC_filts[type_val][1, 1])]])\n",
    "\n",
    "    TN_MQC[type_val], FP_MQC[type_val], FN_MQC[type_val], TP_MQC[type_val] = cm_mat_MQC[type_val].flatten().astype('float32')\n",
    "\n",
    "    MCC_MQC[type_val]    = MCC_from_CM(cm_mat_MQC[type_val])\n",
    "\n",
    "    ACC_MQC[type_val]    = ACC_from_CM(cm_mat_MQC[type_val])\n",
    "\n",
    "    F1_MQC[type_val]     = F1_from_CM(cm_mat_MQC[type_val])\n",
    "\n",
    "    Recall_MQC[type_val] = Recall_from_CM(cm_mat_MQC[type_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89103a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mat_AGN_filts = np.array([[(np.array(data_pred_AGN_all['is_AGN'] == 0) & np.array(data_pred_AGN_all['Label_AGN'] == 0)),\\\n",
    "                        (np.array(data_pred_AGN_all['is_AGN'] == 0) & np.array(data_pred_AGN_all['Label_AGN'] == 1))],\\\n",
    "                       [(np.array(data_pred_AGN_all['is_AGN'] == 1) & np.array(data_pred_AGN_all['Label_AGN'] == 0)),\\\n",
    "                        (np.array(data_pred_AGN_all['is_AGN'] == 1) & np.array(data_pred_AGN_all['Label_AGN'] == 1))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mat_AGN_all = np.array([[np.sum(cm_mat_AGN_filts[0, 0]),\\\n",
    "                        np.sum(cm_mat_AGN_filts[0, 1])],\\\n",
    "                       [np.sum(cm_mat_AGN_filts[1, 0]),\\\n",
    "                        np.sum(cm_mat_AGN_filts[1, 1])]])\n",
    "\n",
    "cm_mat_AGN_train = np.array([[np.sum(cm_mat_AGN_filts[0, 0] * subset_filters_df.loc[:, 'train']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[0, 1] * subset_filters_df.loc[:, 'train'])],\\\n",
    "                       [np.sum(cm_mat_AGN_filts[1, 0] * subset_filters_df.loc[:, 'train']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[1, 1] * subset_filters_df.loc[:, 'train'])]])\n",
    "\n",
    "cm_mat_AGN_test = np.array([[np.sum(cm_mat_AGN_filts[0, 0] * subset_filters_df.loc[:, 'test']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[0, 1] * subset_filters_df.loc[:, 'test'])],\\\n",
    "                       [np.sum(cm_mat_AGN_filts[1, 0] * subset_filters_df.loc[:, 'test']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[1, 1] * subset_filters_df.loc[:, 'test'])]])\n",
    "\n",
    "cm_mat_AGN_val = np.array([[np.sum(cm_mat_AGN_filts[0, 0] * subset_filters_df.loc[:, 'validation']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[0, 1] * subset_filters_df.loc[:, 'validation'])],\\\n",
    "                       [np.sum(cm_mat_AGN_filts[1, 0] * subset_filters_df.loc[:, 'validation']),\\\n",
    "                        np.sum(cm_mat_AGN_filts[1, 1] * subset_filters_df.loc[:, 'validation'])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03701ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN_AGN_all,   FP_AGN_all,   FN_AGN_all,   TP_AGN_all   = cm_mat_AGN_all.flatten().astype('float32')\n",
    "TN_AGN_train, FP_AGN_train, FN_AGN_train, TP_AGN_train = cm_mat_AGN_train.flatten().astype('float32')\n",
    "TN_AGN_test,  FP_AGN_test,  FN_AGN_test,  TP_AGN_test  = cm_mat_AGN_test.flatten().astype('float32')\n",
    "TN_AGN_val,   FP_AGN_val,   FN_AGN_val,   TP_AGN_val   = cm_mat_AGN_val.flatten().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12579d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC_AGN_all      = MCC_from_CM(cm_mat_AGN_all)\n",
    "MCC_AGN_train    = MCC_from_CM(cm_mat_AGN_all)\n",
    "MCC_AGN_test     = MCC_from_CM(cm_mat_AGN_all)\n",
    "MCC_AGN_val      = MCC_from_CM(cm_mat_AGN_all)\n",
    "\n",
    "ACC_AGN_all      = ACC_from_CM(cm_mat_AGN_train)\n",
    "ACC_AGN_train    = ACC_from_CM(cm_mat_AGN_train)\n",
    "ACC_AGN_test     = ACC_from_CM(cm_mat_AGN_train)\n",
    "ACC_AGN_val      = ACC_from_CM(cm_mat_AGN_train)\n",
    "\n",
    "F1_AGN_all       = F1_from_CM(cm_mat_AGN_test)\n",
    "F1_AGN_train     = F1_from_CM(cm_mat_AGN_test)\n",
    "F1_AGN_test      = F1_from_CM(cm_mat_AGN_test)\n",
    "F1_AGN_val       = F1_from_CM(cm_mat_AGN_test)\n",
    "\n",
    "Recall_AGN_all   = Recall_from_CM(cm_mat_AGN_val)\n",
    "Recall_AGN_train = Recall_from_CM(cm_mat_AGN_val)\n",
    "Recall_AGN_test  = Recall_from_CM(cm_mat_AGN_val)\n",
    "Recall_AGN_val   = Recall_from_CM(cm_mat_AGN_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_val in MQC_types:\n",
    "    print('-' * 50)\n",
    "    print(f'Scores for MQC                     TYPE = {type_val}')\n",
    "    print('Metrics for AGN detection in full dataset:')\n",
    "    print(f'F1-score is                          F1 = {F1_MQC[type_val]:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient is MCC = {MCC_MQC[type_val]:.4f}')\n",
    "    print(f'Recall is                           TPR = {Recall_MQC[type_val]:.4f}')\n",
    "    print(f'Accuracy is                         ACC = {ACC_MQC[type_val]:.4f}')\n",
    "    print('-' * 50  + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-' * 50)\n",
    "print('Metrics for AGN detection in full dataset:')\n",
    "print(f'F1-score is                          F1 = {F1_AGN_all:.4f}')\n",
    "print(f'Matthews Correlation Coefficient is MCC = {MCC_AGN_all:.4f}')\n",
    "print(f'Recall is                           TPR = {Recall_AGN_all:.4f}')\n",
    "print(f'Accuracy is                         ACC = {ACC_AGN_all:.4f}')\n",
    "print('-' * 50  + '\\n')\n",
    "print('-' * 50  + '\\n')\n",
    "print('Metrics for AGN detection in training sub-set:')\n",
    "print(f'F1-score is                          F1 = {F1_AGN_train:.4f}')\n",
    "print(f'Matthews Correlation Coefficient is MCC = {MCC_AGN_train:.4f}')\n",
    "print(f'Recall is                           TPR = {Recall_AGN_train:.4f}')\n",
    "print(f'Accuracy is                         ACC = {ACC_AGN_train:.4f}')\n",
    "print('-' * 50  + '\\n')\n",
    "print('-' * 50  + '\\n')\n",
    "print('Metrics for AGN detection in testing sub-set:')\n",
    "print(f'F1-score is                          F1 = {F1_AGN_test:.4f}')\n",
    "print(f'Matthews Correlation Coefficient is MCC = {MCC_AGN_test:.4f}')\n",
    "print(f'Recall is                           TPR = {Recall_AGN_test:.4f}')\n",
    "print(f'Accuracy is                         ACC = {ACC_AGN_test:.4f}')\n",
    "print('-' * 50  + '\\n')\n",
    "print('-' * 50  + '\\n')\n",
    "print('Metrics for AGN detection in validation sub-set:')\n",
    "print(f'F1-score is                          F1 = {F1_AGN_val:.4f}')\n",
    "print(f'Matthews Correlation Coefficient is MCC = {MCC_AGN_val:.4f}')\n",
    "print(f'Recall is                           TPR = {Recall_AGN_val:.4f}')\n",
    "print(f'Accuracy is                         ACC = {ACC_AGN_val:.4f}')\n",
    "print('-' * 50  + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_val in MQC_types:\n",
    "    fig             = plt.figure(figsize=(6,5))\n",
    "    ax1             = fig.add_subplot(111)\n",
    "    \n",
    "    plot_conf_mat(cm_mat_MQC[type_val], title=f'TYPE = {type_val}', axin=ax1, display_labels=['Non\\nAGN', 'AGN'], log_stretch=True)\n",
    "    if save_plot_flag:\n",
    "        plt.savefig(f'plots/confusion_matrix_AGN_{type_val}_{used_dataset}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44236b8b",
   "metadata": {},
   "source": [
    "### Use squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe12e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_types_full   = []  # full dataset, no confusion matrix\n",
    "used_types_full    = []\n",
    "list_types    = ['Q', 'A', 'B', 'L', 'K', 'N']\n",
    "for type_val in list_types:\n",
    "    n_elems = np.sum(np.array(data_pred_AGN_all[f'is_{type_val}'] == 1))\n",
    "    if n_elems == 0:\n",
    "        continue\n",
    "    used_types_full.append(type_val)\n",
    "    sizes_types_full.append(np.sum(np.array(data_pred_AGN_all[f'is_{type_val}'] == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab318ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ll   = plt.get_cmap('cet_CET_L8', len(used_types_full))\n",
    "color_list = [mcolors.rgb2hex(color_ll(i)) for i in range(color_ll.N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,7))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='linear')\n",
    "\n",
    "sq_plt = squarify.plot(sizes_types_full, label=used_types_full, ax=ax1, pad=True,\\\n",
    "                       text_kwargs={'fontsize': 18, 'path_effects': pe2}, color=color_list)\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.tick_params(which='both', top=False, right=False, bottom=False, left=False, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=2.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_empty_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18590ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_types   = []\n",
    "list_types    = list(np.unique(data_pred_AGN_all.loc[:, 'TYPE']))\n",
    "if not show_empty_flag:\n",
    "    list_types.remove('    ')\n",
    "for type_val in list_types:\n",
    "    sizes_types.append(np.sum(data_pred_AGN_all.loc[:, 'TYPE'].str.contains(type_val, regex=False)))\n",
    "\n",
    "color_ll   = plt.get_cmap('cet_CET_L8', len(list_types))\n",
    "color_list = [mcolors.rgb2hex(color_ll(i)) for i in range(color_ll.N)]\n",
    "\n",
    "if show_empty_flag:\n",
    "    list_types[:] = ['0   ' if x=='    ' else x for x in list_types]\n",
    "\n",
    "fig             = plt.figure(figsize=(7,7))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='linear')\n",
    "\n",
    "sq_plt = squarify.plot(sizes_types, label=list_types, ax=ax1, pad=True,\\\n",
    "                       text_kwargs={'fontsize': 18, 'path_effects': pe2}, color=color_list)\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.tick_params(which='both', top=False, right=False, bottom=False, left=False, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=2.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "\n",
    "fig             = plt.figure(figsize=(3 * n_cols, 3 * n_rows), constrained_layout=True)\n",
    "\n",
    "grid            = fig.add_gridspec(ncols=n_cols, nrows=n_rows, width_ratios=[1]*n_cols,\\\n",
    "                                   height_ratios=[1]*n_rows, hspace=0.001, wspace=0.0)\n",
    "axs             = {}\n",
    "\n",
    "list_types    = ['Q', 'A', 'B', 'L', 'K', 'N']\n",
    "color_ll      = plt.get_cmap('cet_CET_L8', len(list_types))\n",
    "color_list    = {list_types[i]: mcolors.rgb2hex(color_ll(i)) for i in range(color_ll.N)}\n",
    "\n",
    "\n",
    "for count, idx_ax in enumerate(np.array([[0, 0], [0, 1], [1, 0], [1, 1]])):\n",
    "    axs[count]     = fig.add_subplot(grid[count], xscale='linear', yscale='linear')\n",
    "    \n",
    "    list_types_tmp = ['Q', 'A', 'B', 'L', 'K', 'N']\n",
    "    sizes_types    = []\n",
    "    used_types     = []\n",
    "    for type_val in list_types_tmp:\n",
    "        n_sources  = np.sum(np.array(data_pred_AGN_all[f'is_{type_val}'] == 1) & cm_mat_AGN_filts[tuple(idx_ax)])\n",
    "        if n_sources == 0:\n",
    "            continue\n",
    "        sizes_types.append(n_sources)\n",
    "        used_types.append(type_val)\n",
    "    \n",
    "    color_list_tmp = [color_list[elem] for elem in used_types]\n",
    "    \n",
    "    sq_plt = squarify.plot(sizes_types, label=used_types, ax=axs[count], pad=True,\\\n",
    "                       text_kwargs={'fontsize': 18, 'path_effects': pe2}, color=color_list_tmp)\n",
    "    \n",
    "    axs[count].get_xaxis().set_ticks([])\n",
    "    axs[count].get_yaxis().set_ticks([])\n",
    "    axs[count].tick_params(which='both', top=False, right=False,\\\n",
    "                           bottom=False, left=False, direction='in')\n",
    "    axs[count].tick_params(axis='both', which='major', labelsize=14)\n",
    "    axs[count].tick_params(axis='both', which='minor', labelsize=14)\n",
    "    axs[count].tick_params(which='major', length=8, width=1.5)\n",
    "    axs[count].tick_params(which='minor', length=4, width=1.5)\n",
    "    plt.setp(axs[count].spines.values(), linewidth=2.5)\n",
    "    plt.setp(axs[count].spines.values(), linewidth=2.5)\n",
    "\n",
    "axs[0].set_ylabel('No\\nAGN', fontsize=18, rotation='horizontal', labelpad=25)\n",
    "axs[2].set_xlabel('No\\nAGN', fontsize=18)\n",
    "axs[2].set_ylabel('AGN', fontsize=18, rotation='horizontal', labelpad=25)\n",
    "axs[3].set_xlabel('AGN', fontsize=18)\n",
    "\n",
    "fig.supxlabel('Predicted label', fontsize=20, ha='left', x=0.4)\n",
    "fig.supylabel('True label', fontsize=20, va='bottom', y=0.45)\n",
    "# fig.suptitle('Predicted values', fontsize=16)\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig('plots/conf_matrix_treeplot_AGN_MQC_TYPE_{used_dataset}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd6b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb252f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcabc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987ea35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f32cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169551b8-6f55-46e6-bbea-f7438e5a2157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b03031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b3d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9876980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b074e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HETDEX_pipeline_AGN_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
