{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for High-z Radio Galaxies 12: Application of full pipeline for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, three models will be applied consecutively in order to predict  \n",
    "the detection of Radio Galaxies (radio AGN) and their redshift.  \n",
    "\n",
    "In principle, this pipeline should be applied to data in Stripe 82. But  \n",
    "it can be used with any other suitable dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as mpe\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from astropy.visualization import LogStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import sklearn.pipeline\n",
    "import colorcet as cc\n",
    "from pycaret import classification as pyc\n",
    "from pycaret import regression as pyr\n",
    "from pycaret.internal.tabular import _get_columns_to_stratify_by\n",
    "import pandas as pd\n",
    "import mpl_scatter_density\n",
    "import schemdraw\n",
    "from schemdraw import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create path effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe1            = [mpe.Stroke(linewidth=5.0, foreground='black'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]\n",
    "pe2            = [mpe.Stroke(linewidth=3.0, foreground='white'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define specific metrics for redshift values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_mad(z_true, z_pred, **kwargs):\n",
    "    med = np.nanmedian(np.abs(z_true - z_pred)).astype('float32')\n",
    "    return 1.48 * med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_nmad(z_true, z_pred, **kwargs):\n",
    "    dif  = (z_true - z_pred)\n",
    "    frac = dif / (1 + z_true).values\n",
    "    med  = np.nanmedian(np.abs(frac)).astype('float32')\n",
    "    return 1.48 * med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_z(z_true, z_pred, **kwargs):\n",
    "    dif = z_true - z_pred\n",
    "    ssq = np.sum(dif**2)\n",
    "    rot = np.sqrt(ssq / len(z_true)).astype('float32')\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_z_norm(z_true, z_pred, **kwargs):\n",
    "    dif = (z_true - z_pred) / (1 + z_true)\n",
    "    ssq = np.sum(dif**2)\n",
    "    rot = np.sqrt(ssq / len(z_true)).astype('float32')\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def outlier_frac(z_true, z_pred, **kwargs):\n",
    "    dif  = np.abs((z_true - z_pred) / (1 + z_true))\n",
    "    siz  = np.sum(np.isfinite(dif)).astype('float32')\n",
    "    num  = np.sum(np.array(dif > 0.15)).astype('float32')\n",
    "    frac = num / siz\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for Pycaret and saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_final_column_names(pycaret_pipeline, sample_df):\n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        for (name, method) in pycaret_pipeline.named_steps.items():\n",
    "            if method != 'passthrough' and name != 'trained_model':\n",
    "                print(f'Running {name}')\n",
    "                sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()\n",
    "    else:\n",
    "        try:\n",
    "            for (name, method) in pyr.get_config('prep_pipe').named_steps.items():\n",
    "                if method != 'passthrough' and name != 'trained_model':\n",
    "                    print(f'Running {name}')\n",
    "                    sample_df = method.transform(sample_df)\n",
    "        except:\n",
    "            for (name, method) in pyc.get_config('prep_pipe').named_steps.items():\n",
    "                if method != 'passthrough' and name != 'trained_model':\n",
    "                    print(f'Running {name}')\n",
    "                    sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_importances_df(pycaret_pipeline, sample_df, n = 10):\n",
    "    \n",
    "    final_cols = get_final_column_names(pycaret_pipeline, sample_df)\n",
    "    \n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        try:\n",
    "            variables = pycaret_pipeline[\"trained_model\"].feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline[\"trained_model\"].estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            variables = pycaret_pipeline.feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline.estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for the use of values in Confusion Matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCC_from_CM(cm_array):  # Matthews correlation coefficient\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ACC_from_CM(cm_array):  # Accuracy\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F1_from_CM(cm_array):  # F-1 score\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Recall_from_CM(cm_array):  # Recall\n",
    "    TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    Recall = TP / (TP + FN)\n",
    "    return Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_conf_mat(confusion_matrix, title, axin, display_labels=['Non true', 'True'], cmap='cet_dimgray_r', show_clb=False, log_stretch=False):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,\n",
    "                              display_labels=display_labels)\n",
    "\n",
    "    min_val_colour = np.nanmin(confusion_matrix)\n",
    "    max_val_colour = np.nanmin(confusion_matrix)\n",
    "    \n",
    "    if log_stretch:\n",
    "        norm = ImageNormalize(stretch=LogStretch())\n",
    "    if not log_stretch:\n",
    "        norm = ImageNormalize()\n",
    "\n",
    "    # NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
    "    disp_b = disp.plot(include_values=True, cmap=cm.get_cmap(cmap),\\\n",
    "             ax=axin, xticks_rotation='horizontal')\n",
    "\n",
    "    for text_val in disp_b.text_.flatten():\n",
    "        text_val.set_fontsize(30)\n",
    "    clb = plt.gca().images[-1].colorbar\n",
    "    clb.ax.tick_params(labelsize=14)\n",
    "    clb.ax.ticklabel_format(style='sci', scilimits=(0, 0))\n",
    "    clb.outline.set_linewidth(2.5)\n",
    "    clb.ax.set_ylabel('Elements in bin', size=14)\n",
    "    if not show_clb:\n",
    "        clb.remove()\n",
    "\n",
    "    # disp_b.im_.set_clim(1e2, 3e3)\n",
    "    disp_b.im_.norm = norm\n",
    "\n",
    "    axin.xaxis.get_label().set_fontsize(16)\n",
    "    axin.yaxis.get_label().set_fontsize(16)\n",
    "\n",
    "    axin.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    axin.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_redshift_compare(true_z, predicted_z, ax_pre, title=None, dpi=10, cmap='cet_linear_kryw_5_100_c64_r', show_clb=False, log_stretch=False):\n",
    "    if log_stretch:\n",
    "        norm = ImageNormalize(vmin=0., stretch=LogStretch())\n",
    "    if not log_stretch:\n",
    "        norm = ImageNormalize(vmin=0.)\n",
    "\n",
    "    vmax_dens     = 100\n",
    "\n",
    "    filt_pair_z   = np.isfinite(true_z) & np.isfinite(predicted_z)\n",
    "    max_for_range = np.nanmax([np.nanmax(1 + true_z.loc[filt_pair_z]), np.nanmax(1 + predicted_z.loc[filt_pair_z])])\n",
    "\n",
    "    dens_1 = ax_pre.scatter_density((1 + true_z.sample(frac=1, random_state=seed)),\\\n",
    "            (1 + predicted_z.sample(frac=1, random_state=seed)),\\\n",
    "            cmap=plt.get_cmap(cmap, vmax_dens), zorder=0, dpi=dpi, norm=norm, alpha=0.93)\n",
    "    \n",
    "    ax_pre.axline((2., 2.), (3., 3.), ls='--', marker=None, c='Gray', alpha=0.8, lw=3.0, zorder=20)\n",
    "    ax_pre.axline(xy1=(1., 1.15), xy2=(2., 2.3), ls='-.', marker=None, c='slateblue', alpha=0.6, lw=3.0, zorder=20)\n",
    "    ax_pre.axline(xy1=(1., 0.85), xy2=(2., 1.7), ls='-.', marker=None, c='slateblue', alpha=0.6, lw=3.0, zorder=20)\n",
    "\n",
    "    clb = plt.colorbar(dens_1, extend='neither', norm=norm)\n",
    "    clb.ax.tick_params(labelsize=14)\n",
    "    clb.outline.set_linewidth(2.5)\n",
    "    clb.ax.set_ylabel('Elements per pixel', size=16, path_effects=pe2)\n",
    "\n",
    "    # Inset axis with residuals\n",
    "    axins = inset_axes(ax_pre, width='35%', height='20%', loc=2)\n",
    "    res_z_z = (predicted_z - true_z) / (1 + true_z)\n",
    "    axins.hist(res_z_z, histtype='stepfilled', fc='grey', ec='k', bins=50, lw=2.5)\n",
    "    axins.axvline(x=np.nanpercentile(res_z_z, [15.9]), ls='--', lw=2.5, c='royalblue')\n",
    "    axins.axvline(x=np.nanpercentile(res_z_z, [84.1]), ls='--', lw=2.5, c='royalblue')\n",
    "    axins.set_xlabel('$\\Delta z / (1 + z_{\\mathrm{True}})$', fontsize=10)\n",
    "    axins.tick_params(labelleft=False, labelbottom=True)\n",
    "    axins.tick_params(which='both', top=True, right=True, direction='in')\n",
    "    axins.tick_params(axis='both', which='major', labelsize=10)\n",
    "    axins.tick_params(which='major', length=8, width=1.5)\n",
    "    axins.tick_params(which='minor', length=4, width=1.5)\n",
    "    plt.setp(axins.spines.values(), linewidth=2.5)\n",
    "    plt.setp(axins.spines.values(), linewidth=2.5)\n",
    "    axins.set_xlim(left=-0.9, right=0.9)\n",
    "    ##\n",
    "    ax_pre.set_xlabel('$1 + z_{\\mathrm{True}}$', fontsize=20)\n",
    "    ax_pre.set_ylabel('$1 + z_{\\mathrm{Predicted}}$', fontsize=20)\n",
    "    ax_pre.tick_params(which='both', top=True, right=True, direction='in')\n",
    "    ax_pre.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    ax_pre.tick_params(which='major', length=8, width=1.5)\n",
    "    ax_pre.tick_params(which='minor', length=4, width=1.5)\n",
    "    ax_pre.xaxis.set_minor_formatter(ticker.ScalarFormatter(useMathText=False))\n",
    "    ax_pre.yaxis.set_minor_formatter(ticker.ScalarFormatter(useMathText=False))\n",
    "    plt.setp(ax_pre.spines.values(), linewidth=2.5)\n",
    "    plt.setp(ax_pre.spines.values(), linewidth=2.5)\n",
    "    ax_pre.set_xlim(left=1., right=np.ceil(max_for_range))\n",
    "    ax_pre.set_ylim(bottom=1., top=np.ceil(max_for_range))\n",
    "    ax_pre.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_path = '../../Catalogs/'  # relative path to the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_flag   = False\n",
    "load_models_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_area = 'S82'  # can be 'S82', 'HETDEX', 'COSMOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_S82       = ''\n",
    "file_HETDEX    = 'CatWISE2020_VLASS_LOFAR_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_7_4d_ALLWISE_LOLSS_SDSS_DR16_5sigma_imp.h5'\n",
    "file_COSMOS    = ''\n",
    "\n",
    "file_name_dict = {'S82': file_S82, 'HETDEX': file_HETDEX, 'COSMOS': file_COSMOS}\n",
    "file_name      = file_name_dict[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_2_disc_S82 = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "                     'Sint_LOFAR', 'Stotal_TGSS', 'FEP', 'TotalFlux_LoLSS', 'W1mag', 'W2mag']\n",
    "feats_2_disc_HETDEX = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "                     'Sint_LOFAR', 'Stotal_TGSS', 'FEP', 'TotalFlux_LoLSS', 'W1mag', 'W2mag']\n",
    "feats_2_disc_COSMOS = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "                     'Stotal_TGSS', 'FEP', 'Flux_COSMOSVLA3', 'W1mag', 'W2mag']\n",
    "\n",
    "feats_2_disc = {'S82': feats_2_disc_S82, 'HETDEX': feats_2_disc_HETDEX, 'COSMOS': feats_2_disc_COSMOS}\n",
    "features_2_discard = feats_2_disc[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = pd.read_hdf(cat_path + file_name, key='df').drop(columns=features_2_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df.loc[:, 'radio_detect'] = full_catalog_df.loc[:, 'radio_detect'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features with class and combined redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['class']            = full_catalog_df.loc[:, 'is_AGN'].copy()\n",
    "idx_non_Z                           = full_catalog_df.loc[:, 'Z'].where(full_catalog_df.loc[:, 'Z'] > 0).isna()\n",
    "full_catalog_df.loc[idx_non_Z, 'Z'] = full_catalog_df.loc[:, 'Z'].mask(idx_non_Z, full_catalog_df.loc[idx_non_Z, 'zsp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard minor features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = full_catalog_df.drop(columns=['is_AGN', 'is_SDSS_gal', 'is_gal', 'zsp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_models_flag:\n",
    "    AGN_gal_clf   = pyc.load_model('models/classification_AGN_galaxy_apr_20_2022')\n",
    "    radio_det_clf = pyc.load_model('models/classification_radio_detect_may_09_2022')\n",
    "    redshift_reg  = pyr.load_model('models/regression_z_may_10_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_AGN   = 0.5\n",
    "threshold_radio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = pyc.predict_model(AGN_gal_clf, data=full_catalog_df, probability_threshold=threshold_AGN, raw_score=True)\n",
    "full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_class', 'Score_0': 'Score_gal', 'Score_1': 'Score_AGN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = pyc.predict_model(radio_det_clf, data=full_catalog_df, probability_threshold=threshold_radio, raw_score=True)\n",
    "full_catalog_df = full_catalog_df.drop(columns=['Score_0'])\n",
    "full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_radio', 'Score_1': 'Score_radio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = pyr.predict_model(redshift_reg)\n",
    "full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_Z'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select sources predicted to be Radio AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_radio_AGN_t = np.array(full_catalog_df.loc[:, 'class'] == 1) & np.array(full_catalog_df.loc[:, 'radio_detect'] == 1)\n",
    "total_size         = len(full_catalog_df)\n",
    "num_AGN_t          = np.sum(np.array(full_catalog_df.loc[:, 'class'] == 1))\n",
    "num_radio_t        = np.sum(np.array(full_catalog_df.loc[:, 'radio_detect'] == 1))\n",
    "num_radio_AGN_t    = np.sum(filter_radio_AGN_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_radio_AGN_p = np.array(full_catalog_df.loc[:, 'Score_AGN'] > threshold_AGN) & np.array(full_catalog_df.loc[:, 'Score_radio'] > threshold_radio)\n",
    "full_catalog_df    = full_catalog_df.loc[filter_radio_AGN_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add individual metrics for redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['Delta_z_N'] = np.around((full_catalog_df.loc[:, 'Pred_Z'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)\n",
    "\n",
    "full_catalog_df['sigma_NMAD'] = np.around(1.48 * np.abs(full_catalog_df.loc[:, 'Pred_Z'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AGN_p       = np.sum(np.array(full_catalog_df.loc[:, 'Score_AGN'] > threshold_AGN))\n",
    "num_radio_p     = np.sum(np.array(full_catalog_df.loc[:, 'Score_radio'] > threshold_radio))\n",
    "num_radio_AGN_p = np.sum(filter_radio_AGN_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_0_t = f'Out of {total_size:,} initial sources in {used_area},\\n'\n",
    "str_1_t = f'{num_AGN_t:,} are confirmed to be AGN. And, from them,\\n'\n",
    "str_2_t = f'{num_radio_AGN_t:,} are detected in radio.'\n",
    "\n",
    "str_0_p = f'Out of {total_size:,} initial sources in {used_area},\\n'\n",
    "str_1_p = f'{num_AGN_p:,} are predicted to be AGN. And, from them,\\n'\n",
    "str_2_p = f'{num_radio_AGN_p:,} are predicted to be detected in radio.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-' * 50)\n",
    "print(str_0_t + str_1_t + str_2_t)\n",
    "print('-' * 50)\n",
    "print(str_0_p + str_1_p + str_2_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_4_table = show_columns = ['RA_ICRS', 'DE_ICRS', 'Name', 'TYPE', 'band_num', 'class', 'pred_class', 'radio_detect', 'pred_radio', 'Z', 'Pred_Z', 'Delta_z_N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[:, cols_4_table].sort_values(by='Pred_Z', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_AGN = np.array([[np.sum(np.array(full_catalog_df['class'] == 0) & np.array(full_catalog_df['pred_class'] == 0)),\\\n",
    "          np.sum(np.array(full_catalog_df['class'] == 0) & np.array(full_catalog_df['pred_class'] == 1))],\\\n",
    "        [np.sum(np.array(full_catalog_df['class'] == 1) & np.array(full_catalog_df['pred_class'] == 0)),\\\n",
    "          np.sum(np.array(full_catalog_df['class'] == 1) & np.array(full_catalog_df['pred_class'] == 1))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_radio = np.array([[np.sum(np.array(full_catalog_df['radio_detect'] == 0) & np.array(full_catalog_df['pred_radio'] == 0)),\\\n",
    "          np.sum(np.array(full_catalog_df['radio_detect'] == 0) & np.array(full_catalog_df['pred_radio'] == 1))],\\\n",
    "        [np.sum(np.array(full_catalog_df['radio_detect'] == 1) & np.array(full_catalog_df['pred_radio'] == 0)),\\\n",
    "          np.sum(np.array(full_catalog_df['radio_detect'] == 1) & np.array(full_catalog_df['pred_radio'] == 1))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC_AGN    = MCC_from_CM(cm_AGN)\n",
    "ACC_AGN    = ACC_from_CM(cm_AGN)\n",
    "F1_AGN     = F1_from_CM(cm_AGN)\n",
    "Recall_AGN = Recall_from_CM(cm_AGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC_radio    = MCC_from_CM(cm_radio)\n",
    "ACC_radio    = ACC_from_CM(cm_radio)\n",
    "F1_radio     = F1_from_CM(cm_radio)\n",
    "Recall_radio = Recall_from_CM(cm_radio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mad_field    = sigma_mad(full_catalog_df.loc[:, 'Z'],    full_catalog_df.loc[:, 'Pred_Z'])\n",
    "sigma_nmad_field   = sigma_nmad(full_catalog_df.loc[:, 'Z'],   full_catalog_df.loc[:, 'Pred_Z'])\n",
    "sigma_z_field      = sigma_z(full_catalog_df.loc[:, 'Z'],      full_catalog_df.loc[:, 'Pred_Z'])\n",
    "sigma_z_norm_field = sigma_z_norm(full_catalog_df.loc[:, 'Z'], full_catalog_df.loc[:, 'Pred_Z'])\n",
    "out_frac_field     = outlier_frac(full_catalog_df.loc[:, 'Z'], full_catalog_df.loc[:, 'Pred_Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_AGN, title=used_area, axin=ax1, display_labels=['Galaxy', 'AGN'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_AGN_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_radio, title=used_area, axin=ax1, display_labels=['No\\nRadio', 'Radio'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_radio_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_redshift_compare(full_catalog_df.loc[:, 'Z'], full_catalog_df.loc[:, 'Pred_Z'], ax_pre=ax1, title=None, dpi=10, show_clb=True, log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/compare_redshift_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
