{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for High-z Radio Galaxies 12: Application of full pipeline for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, three models will be applied consecutively in order to predict  \n",
    "the detection of Radio Galaxies (radio AGN) and their redshift.  \n",
    "\n",
    "In principle, this pipeline should be applied to data in Stripe 82. But  \n",
    "it can be used with any other suitable dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as mpe\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from astropy.visualization import LogStretch, PowerStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.pipeline\n",
    "import colorcet as cc\n",
    "from pycaret import classification as pyc\n",
    "from pycaret import regression as pyr\n",
    "from pycaret.internal.tabular import _get_columns_to_stratify_by\n",
    "import pandas as pd\n",
    "import mpl_scatter_density\n",
    "# import schemdraw\n",
    "# from schemdraw import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create path effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe1            = [mpe.Stroke(linewidth=5.0, foreground='black'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]\n",
    "pe2            = [mpe.Stroke(linewidth=3.0, foreground='white'),\n",
    "                  mpe.Stroke(foreground='white', alpha=1),\n",
    "                  mpe.Normal()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define specific metrics for redshift values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_mad(z_true, z_pred, **kwargs):\n",
    "    try:\n",
    "        med = np.nanmedian(np.abs(z_true - z_pred)).astype('float32')\n",
    "    except:\n",
    "        med = np.nanmedian(np.abs(z_true - z_pred))\n",
    "    return 1.48 * med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_nmad(z_true, z_pred, **kwargs):\n",
    "    dif  = (z_true - z_pred)\n",
    "    frac = dif / (1 + z_true).values\n",
    "    try:\n",
    "        med  = np.nanmedian(np.abs(frac)).astype('float32')\n",
    "    except:\n",
    "        med  = np.nanmedian(np.abs(frac))\n",
    "    return 1.48 * med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_z(z_true, z_pred, **kwargs):\n",
    "    dif = z_true - z_pred\n",
    "    ssq = np.sum(dif**2)\n",
    "    try:\n",
    "        rot = np.sqrt(ssq / len(z_true)).astype('float32')\n",
    "    except:\n",
    "        rot = np.sqrt(ssq / len(z_true))\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigma_z_norm(z_true, z_pred, **kwargs):\n",
    "    dif = (z_true - z_pred) / (1 + z_true)\n",
    "    ssq = np.sum(dif**2)\n",
    "    try:\n",
    "        rot = np.sqrt(ssq / len(z_true)).astype('float32')\n",
    "    except:\n",
    "        rot = np.sqrt(ssq / len(z_true))\n",
    "    return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def outlier_frac(z_true, z_pred, **kwargs):\n",
    "    dif  = np.abs((z_true - z_pred) / (1 + z_true))\n",
    "    try:\n",
    "        siz  = np.sum(np.isfinite(dif)).astype('float32')\n",
    "        num  = np.sum(np.array(dif > 0.15)).astype('float32')\n",
    "    except:\n",
    "        siz  = np.sum(np.isfinite(dif))\n",
    "        num  = np.sum(np.array(dif > 0.15))\n",
    "    frac = num / siz\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for Pycaret and saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_final_column_names(pycaret_pipeline, sample_df):\n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        for (name, method) in pycaret_pipeline.named_steps.items():\n",
    "            if method != 'passthrough' and name != 'trained_model':\n",
    "                print(f'Running {name}')\n",
    "                sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()\n",
    "    else:\n",
    "        try:\n",
    "            for (name, method) in pyr.get_config('prep_pipe').named_steps.items():\n",
    "                if method != 'passthrough' and name != 'trained_model':\n",
    "                    print(f'Running {name}')\n",
    "                    sample_df = method.transform(sample_df)\n",
    "        except:\n",
    "            for (name, method) in pyc.get_config('prep_pipe').named_steps.items():\n",
    "                if method != 'passthrough' and name != 'trained_model':\n",
    "                    print(f'Running {name}')\n",
    "                    sample_df = method.transform(sample_df)\n",
    "        return sample_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_importances_df(pycaret_pipeline, sample_df, n = 10):\n",
    "    \n",
    "    final_cols = get_final_column_names(pycaret_pipeline, sample_df)\n",
    "    \n",
    "    if isinstance(pycaret_pipeline, sklearn.pipeline.Pipeline):\n",
    "        try:\n",
    "            variables = pycaret_pipeline[\"trained_model\"].feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline[\"trained_model\"].estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            variables = pycaret_pipeline.feature_importances_\n",
    "            \n",
    "        except:\n",
    "            variables = np.mean([\n",
    "                            tree.feature_importances_ for tree in pycaret_pipeline.estimators_\n",
    "                if hasattr(tree, 'feature_importances_')\n",
    "                            ], axis=0)\n",
    "        \n",
    "        coef_df = pd.DataFrame({'Feature': final_cols, 'Importance': variables})\n",
    "        sorted_df = (\n",
    "            coef_df.sort_values(by='Importance', ascending=False)\n",
    "            .head(n)\n",
    "            .sort_values(by='Importance', ascending=True).reset_index(drop=True)\n",
    "        )\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for the use of values in Confusion Matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def flatten_CM(cm_array):\n",
    "    try:\n",
    "        TN, FP, FN, TP = cm_array.flatten().astype('float32')\n",
    "    except:\n",
    "        TN, FP, FN, TP = cm_array.flatten()\n",
    "    return TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCC_from_CM(cm_array):  # Matthews correlation coefficient\n",
    "    TN, FP, FN, TP = flatten_CM(cm_array)\n",
    "    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ACC_from_CM(cm_array):  # Accuracy\n",
    "    TN, FP, FN, TP = flatten_CM(cm_array)\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F1_from_CM(cm_array):  # F-1 score\n",
    "    TN, FP, FN, TP = flatten_CM(cm_array)\n",
    "    F1 = 2 * TP / (2 * TP + FP + FN)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Recall_from_CM(cm_array):  # Recall\n",
    "    TN, FP, FN, TP = flatten_CM(cm_array)\n",
    "    Recall = TP / (TP + FN)\n",
    "    return Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_conf_mat(confusion_matrix, title, axin, display_labels=['Non true', 'True'], cmap='cet_dimgray_r', show_clb=False, log_stretch=False):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=display_labels)\n",
    "\n",
    "    min_val_colour = np.nanmin(confusion_matrix)\n",
    "    max_val_colour = np.nanmin(confusion_matrix)\n",
    "    \n",
    "    if log_stretch:\n",
    "        norm = ImageNormalize(stretch=LogStretch())\n",
    "    if not log_stretch:\n",
    "        norm = ImageNormalize(stretch=PowerStretch(0.35))\n",
    "\n",
    "    # NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
    "    disp_b = disp.plot(include_values=True, cmap=cm.get_cmap(cmap),\\\n",
    "             ax=axin, xticks_rotation='horizontal', values_format=',')\n",
    "\n",
    "    for text_val in disp_b.text_.flatten():\n",
    "        text_val.set_fontsize(28)\n",
    "    clb = plt.gca().images[-1].colorbar\n",
    "    clb.ax.tick_params(labelsize=14)\n",
    "    clb.ax.ticklabel_format(style='sci', scilimits=(0, 0))\n",
    "    clb.outline.set_linewidth(2.5)\n",
    "    clb.ax.set_ylabel('Elements in bin', size=14)\n",
    "    if not show_clb:\n",
    "        clb.remove()\n",
    "\n",
    "    # disp_b.im_.set_clim(1e2, 3e3)\n",
    "    disp_b.im_.norm = norm\n",
    "\n",
    "    axin.xaxis.get_label().set_fontsize(16)\n",
    "    axin.yaxis.get_label().set_fontsize(16)\n",
    "\n",
    "    axin.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    plt.setp(axin.spines.values(), linewidth=2.5)\n",
    "    axin.set_title(title, fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to plot predicted and true redshift values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_redshift_compare(true_z, predicted_z, ax_pre, title=None, dpi=10, cmap='cet_linear_kryw_5_100_c64_r', show_clb=False, log_stretch=False):\n",
    "    if log_stretch:\n",
    "        norm = ImageNormalize(vmin=0., stretch=LogStretch())\n",
    "    if not log_stretch:\n",
    "        norm = ImageNormalize(vmin=0., stretch=PowerStretch(0.5))\n",
    "\n",
    "    filt_pair_z   = np.isfinite(true_z) & np.isfinite(predicted_z)\n",
    "    max_for_range = np.nanmax([np.nanmax(1 + true_z.loc[filt_pair_z]), np.nanmax(1 + predicted_z.loc[filt_pair_z])])\n",
    "\n",
    "    dens_1 = ax_pre.scatter_density((1 + true_z.sample(frac=1, random_state=seed)),\\\n",
    "            (1 + predicted_z.sample(frac=1, random_state=seed)),\\\n",
    "            cmap=plt.get_cmap(cmap), zorder=0, dpi=dpi, norm=norm, alpha=0.93)\n",
    "    \n",
    "    ax_pre.axline((2., 2.), (3., 3.), ls='--', marker=None, c='Gray', alpha=0.8, lw=3.0, zorder=20)\n",
    "    ax_pre.axline(xy1=(1., 1.15), xy2=(2., 2.3), ls='-.', marker=None, c='slateblue', alpha=0.6, lw=3.0, zorder=20)\n",
    "    ax_pre.axline(xy1=(1., 0.85), xy2=(2., 1.7), ls='-.', marker=None, c='slateblue', alpha=0.6, lw=3.0, zorder=20)\n",
    "\n",
    "    if show_clb:\n",
    "        clb = plt.colorbar(dens_1, extend='neither', norm=norm, ticks=ticker.MaxNLocator(integer=True))\n",
    "        clb.ax.tick_params(labelsize=14)\n",
    "        clb.outline.set_linewidth(2.5)\n",
    "        clb.ax.set_ylabel('Elements per pixel', size=16, path_effects=pe2)\n",
    "\n",
    "    # Inset axis with residuals\n",
    "    axins = inset_axes(ax_pre, width='35%', height='20%', loc=2)\n",
    "    res_z_z = (predicted_z - true_z) / (1 + true_z)\n",
    "    axins.hist(res_z_z, histtype='stepfilled', fc='grey', ec='k', bins=50, lw=2.5)\n",
    "    axins.axvline(x=np.nanpercentile(res_z_z, [15.9]), ls='--', lw=2.5, c='royalblue')\n",
    "    axins.axvline(x=np.nanpercentile(res_z_z, [84.1]), ls='--', lw=2.5, c='royalblue')\n",
    "    axins.set_xlabel('$\\Delta z / (1 + z_{\\mathrm{True}})$', fontsize=10)\n",
    "    axins.tick_params(labelleft=False, labelbottom=True)\n",
    "    axins.tick_params(which='both', top=True, right=True, direction='in')\n",
    "    axins.tick_params(axis='both', which='major', labelsize=10)\n",
    "    axins.tick_params(which='major', length=8, width=1.5)\n",
    "    axins.tick_params(which='minor', length=4, width=1.5)\n",
    "    plt.setp(axins.spines.values(), linewidth=2.5)\n",
    "    plt.setp(axins.spines.values(), linewidth=2.5)\n",
    "    axins.set_xlim(left=-0.9, right=0.9)\n",
    "    ##\n",
    "    ax_pre.set_xlabel('$1 + z_{\\mathrm{True}}$', fontsize=20)\n",
    "    ax_pre.set_ylabel('$1 + z_{\\mathrm{Predicted}}$', fontsize=20)\n",
    "    ax_pre.tick_params(which='both', top=True, right=True, direction='in')\n",
    "    ax_pre.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    ax_pre.tick_params(which='major', length=8, width=1.5)\n",
    "    ax_pre.tick_params(which='minor', length=4, width=1.5)\n",
    "    # ax_pre.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "    # ax_pre.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "    ax_pre.xaxis.set_minor_formatter(ticker.ScalarFormatter(useMathText=False))\n",
    "    ax_pre.yaxis.set_minor_formatter(ticker.ScalarFormatter(useMathText=False))\n",
    "    plt.setp(ax_pre.spines.values(), linewidth=2.5)\n",
    "    plt.setp(ax_pre.spines.values(), linewidth=2.5)\n",
    "    ax_pre.set_xlim(left=1., right=np.ceil(max_for_range))\n",
    "    ax_pre.set_ylim(bottom=1., top=np.ceil(max_for_range))\n",
    "    ax_pre.set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_star(catalog_df, star_model, threshold, raw_score=True):\n",
    "    catalog_df = pyc.predict_model(star_model, data=catalog_df, probability_threshold=threshold, raw_score=raw_score, round=10)\n",
    "    catalog_df = catalog_df.drop(columns=['Score_1'])\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_star', 'Score_0': 'Score_no_star'})\n",
    "    catalog_df.loc[:, 'Score_no_star'] = np.around(catalog_df.loc[:, 'Score_no_star'], decimals=7)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_AGN_gal(catalog_df, AGN_gal_model, threshold, raw_score=True):\n",
    "    catalog_df = pyc.predict_model(AGN_gal_model, data=catalog_df, probability_threshold=threshold, raw_score=raw_score, round=10)\n",
    "    catalog_df = catalog_df.drop(columns=['Score_0'])\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_class', 'Score_1': 'Score_AGN'})\n",
    "    catalog_df.loc[:, 'Score_AGN'] = np.around(catalog_df.loc[:, 'Score_AGN'], decimals=7)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_radio_det(catalog_df, radio_model, threshold, raw_score=True):\n",
    "    catalog_df = pyc.predict_model(radio_model, data=catalog_df, probability_threshold=threshold, raw_score=raw_score, round=10)\n",
    "    catalog_df = catalog_df.drop(columns=['Score_0'])\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_radio', 'Score_1': 'Score_radio'})\n",
    "    catalog_df.loc[:, 'Score_radio'] = np.around(catalog_df.loc[:, 'Score_radio'], decimals=7)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_z_full(catalog_df, redshift_model):\n",
    "    catalog_df = pyr.predict_model(redshift_model, data=catalog_df, round=10)\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_Z'})\n",
    "    catalog_df.loc[:, 'pred_Z'] = np.around(catalog_df.loc[:, 'pred_Z'], decimals=4)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_z_high(catalog_df, redshift_model, z_lim, z_tol):\n",
    "    catalog_df    = pyr.predict_model(redshift_model, data=catalog_df, round=10)\n",
    "    filter_pred_z = catalog_df.loc[:, 'pred_Z'] >= (z_lim + z_tol)\n",
    "    catalog_df.loc[:, 'pred_Z'] = catalog_df.loc[:, 'pred_Z'].mask(filter_pred_z, catalog_df.loc[filter_pred_z, 'Label'])\n",
    "    catalog_df    = catalog_df.drop(columns=['Label'])\n",
    "    catalog_df.loc[:, 'pred_Z'] = np.around(catalog_df.loc[:, 'pred_Z'], decimals=4)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_AGN_criteria(catalog_df):\n",
    "    catalog_df['M12_AGN'] = M12_AGN_criterion(catalog_df)\n",
    "    catalog_df['S12_AGN'] = S12_AGN_criterion(catalog_df)\n",
    "    catalog_df['M16_AGN'] = M16_AGN_criterion(catalog_df)\n",
    "    catalog_df['B18_AGN'] = B18_AGN_criterion(catalog_df)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M12_AGN_criterion(catalog_df):\n",
    "    M12_column = (np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 <\n",
    "                           0.315 * (catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174) + 0.791) &\n",
    "                  np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 >\n",
    "                           0.315 * (catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174) - 0.222) &\n",
    "                  np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 >\n",
    "                           -3.172 * (catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174) + 7.624)).astype(int)\n",
    "    return M1_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S12_AGN_criterion(catalog_df):\n",
    "    S12_column = np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 >= 0.8).astype(int)\n",
    "    return S12_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M16_AGN_criterion(catalog_df):\n",
    "    M16_column = (np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 > 0.5) &\n",
    "                  np.array(catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174 < 4.4)).astype(int)\n",
    "    return M16_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B18_AGN_criterion(catalog_df):\n",
    "    B18_column = (np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 > 0.5) &\n",
    "                  np.array(catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174 > 2.2) &\n",
    "                  np.array(catalog_df.loc[:, 'W1mproPM'] - catalog_df.loc[:, 'W2mproPM'] - 2.699 + 3.339 >\n",
    "                           2 * (catalog_df.loc[:, 'W2mproPM'] - catalog_df.loc[:, 'W3mag'] - 3.339 + 5.174) - 8.9)).astype(int)\n",
    "    return B18_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_path            = '../../Catalogs/'  # relative path to the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_flag      = False\n",
    "load_models_flag    = True\n",
    "use_zeroth_model    = False  # Initial model to discriminate between star and non-star objects\n",
    "use_second_z_model  = False  # z >= 2.0\n",
    "use_third_z_model   = False  # z >= 3.0\n",
    "use_fourth_z_model  = True  # z >= 3.7 (with SMOGN), or, if needed, z >= 4.0\n",
    "compare_A17_flag    = True  # Compare with the results from Ananna et al., 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_area           = 'HETDEX'  # can be 'S82', 'HETDEX', 'COSMOS'\n",
    "HETDEX_subset       = 'Validation'  # Validation, Training, Test, Test+Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if used_area != 'S82':\n",
    "    compare_A17_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_S82            = 'CatWISE2020_S82_VLASS_VLAS82_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_7_4d_ALLWISE_SDSS_DR16_5sigma_imp.h5'\n",
    "file_HETDEX         = 'CatWISE2020_VLASS_LOFAR_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_7_4d_ALLWISE_LOLSS_SDSS_DR16_5sigma_imp.h5'\n",
    "file_COSMOS         = 'CatWISE2020_COSMOS_MILLIQUAS_7_4d_COSMOSVLA3_PS1_GALEX_TGSS_VLASS_XMM_2MASS_ALLWISE_SDSS_DR16_5sigma_imp.h5'\n",
    "file_S82_Ananna_17  = f'CatWISE2020_S82_VLASS_VLAS82_PS1_GALEX_TGSS_XMM_2MASS_MILLIQUAS_7_4d_ALLWISE_Ananna_17_zsp_5sigma_imp.h5'  # 204 objects\n",
    "\n",
    "file_name_dict      = {'S82': file_S82, 'HETDEX': file_HETDEX, 'COSMOS': file_COSMOS}\n",
    "file_name           = file_name_dict[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feats_2_disc_S82    = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "#                      'Fint_VLAS82', 'Stotal_TGSS', 'FEP', 'W1mag', 'W2mag']\n",
    "# feats_2_disc_HETDEX = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "#                      'Sint_LOFAR', 'Stotal_TGSS', 'FEP', 'TotalFlux_LoLSS', 'W1mag', 'W2mag']\n",
    "# feats_2_disc_COSMOS = ['objID', 'RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'Total_flux_VLASS',\\\n",
    "#                      'Stotal_TGSS', 'FEP', 'Flux_COSMOSVLA3', 'W1mag', 'W2mag']\n",
    "\n",
    "feats_2_disc_S82    = ['RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'W1mag', 'W2mag']\n",
    "feats_2_disc_HETDEX = ['RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'W1mag', 'W2mag']\n",
    "feats_2_disc_COSMOS = ['RA_MILLI', 'DEC_MILLI', 'X_ray_detect', 'W1mag', 'W2mag']\n",
    "\n",
    "feats_2_disc        = {'S82': feats_2_disc_S82, 'HETDEX': feats_2_disc_HETDEX, 'COSMOS': feats_2_disc_COSMOS}\n",
    "features_2_discard  = feats_2_disc[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df     = pd.read_hdf(cat_path + file_name, key='df').drop(columns=features_2_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df.loc[:, 'radio_detect'] = full_catalog_df.loc[:, 'radio_detect'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features with class and combined redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_zeroth_model:\n",
    "    full_catalog_df['is_str'] = np.array(full_catalog_df.loc[:, 'spCl'] == 'STAR  ').astype(int)\n",
    "elif not use_zeroth_model:\n",
    "    full_catalog_df['is_str'] = np.zeros_like(full_catalog_df.loc[:, 'spCl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['class']            = full_catalog_df.loc[:, 'is_AGN'].copy()\n",
    "if use_zeroth_model:\n",
    "    filter_non_confirmed            = np.array(full_catalog_df.loc[:, 'is_AGN'] == 1) |\\\n",
    "                                      np.array(full_catalog_df.loc[:, 'is_gal'] == 1) |\\\n",
    "                                      np.array(full_catalog_df.loc[:, 'is_str'] == 1)\n",
    "    full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'is_str'] == 1), 'class'] = 2\n",
    "elif not use_zeroth_model:\n",
    "    filter_non_confirmed            = np.array(full_catalog_df.loc[:, 'is_AGN'] == 1) |\\\n",
    "                                      np.array(full_catalog_df.loc[:, 'is_gal'] == 1)\n",
    "full_catalog_df.loc[~filter_non_confirmed, 'class'] = 0.5\n",
    "idx_non_Z                           = full_catalog_df.loc[:, 'Z'].where(full_catalog_df.loc[:, 'Z'] > 0).isna()\n",
    "full_catalog_df.loc[idx_non_Z, 'Z'] = full_catalog_df.loc[:, 'Z'].mask(idx_non_Z, full_catalog_df.loc[idx_non_Z, 'zsp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column for detection as Radio AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['radio_AGN']        = np.array(full_catalog_df.loc[:, 'is_AGN'] == 1) & np.array(full_catalog_df.loc[:, 'radio_detect'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed                                = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset if from HETDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of used data in HETDEX\n",
      "(Confirmed galaxies and AGN)\n",
      "--------------------------------------------------\n",
      "Full confirmed dataset size:        (85548, 58)\n",
      "Data for Modeling (Train and Test): (68438, 58)\n",
      "Training data:                      (47906, 58)\n",
      "Testing data:                       (20532, 58)\n",
      "Unseen Data For Validation:         (17110, 58)\n",
      "--------------------------------------------------\n",
      "\n",
      "Using Validation data from HETDEX\n"
     ]
    }
   ],
   "source": [
    "if used_area == 'HETDEX':\n",
    "    if use_zeroth_model:\n",
    "        filter_known_spec = (full_catalog_df.loc[:, 'is_AGN'] == 1) |\\\n",
    "            (full_catalog_df.loc[:, 'is_gal'] == 1) | (full_catalog_df.loc[:, 'is_str'] == 1)\n",
    "    elif not use_zeroth_model:\n",
    "        filter_known_spec = (full_catalog_df.loc[:, 'is_AGN'] == 1) | (full_catalog_df.loc[:, 'is_gal'] == 1)\n",
    "    unknown_cat_df    = full_catalog_df.loc[~filter_known_spec]\n",
    "    full_catalog_df   = full_catalog_df.loc[filter_known_spec]\n",
    "    train_test_df, validation_df     = train_test_split(full_catalog_df, test_size=0.2,\\\n",
    "                                        random_state=seed, stratify=full_catalog_df.loc[:, 'class'])\n",
    "    train_df, test_df                = train_test_split(train_test_df, test_size=0.3,\\\n",
    "                                        random_state=seed, stratify=train_test_df.loc[:, 'class'])\n",
    "    print('Shape of used data in HETDEX')\n",
    "    print('(Confirmed galaxies and AGN)')\n",
    "    print('-' * 50)\n",
    "    print(f'Full confirmed dataset size:        {full_catalog_df.shape}')\n",
    "    print(f'Data for Modeling (Train and Test): {train_test_df.shape}')\n",
    "    print(f'Training data:                      {train_df.shape}')\n",
    "    print(f'Testing data:                       {test_df.shape}')\n",
    "    print(f'Unseen Data For Validation:         {validation_df.shape}')\n",
    "    print('-' * 50)\n",
    "    print()\n",
    "    print(f'Using {HETDEX_subset} data from HETDEX')\n",
    "    selected_dataset = {'Training': train_df, 'Test': test_df, 'Test+Train': train_test_df,\\\n",
    "                        'Validation': validation_df}\n",
    "    full_catalog_df = selected_dataset[HETDEX_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full used dataset size:              (17110, 58)\n",
      "--------------------------------------------------\n",
      "Thus, it has 17,110 sources and 58 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'Full used dataset size:              {full_catalog_df.shape}')\n",
    "print('-' * 50)\n",
    "print(f'Thus, it has {full_catalog_df.shape[0]:,} sources and {full_catalog_df.shape[1]:,} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data if not from HETDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if used_area != 'HETDEX':\n",
    "    filter_confirmed = (full_catalog_df.loc[:, 'class'] == 0) |\\\n",
    "                       (full_catalog_df.loc[:, 'class'] == 1) |\\\n",
    "                       (full_catalog_df.loc[:, 'class'] == 2)  # Galaxy, AGN, star\n",
    "    unknown_cat_df   = full_catalog_df.loc[~filter_confirmed]\n",
    "    full_catalog_df  = full_catalog_df.loc[filter_confirmed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard minor features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df                     = full_catalog_df.drop(columns=['is_AGN', 'is_SDSS_gal', 'is_gal', 'zsp', 'spCl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "if load_models_flag:\n",
    "    if use_zeroth_model:\n",
    "        star_clf        = pyc.load_model('models/classification_star_no_star_jun_30_2022')  # star/no-star model\n",
    "    AGN_gal_clf     = pyc.load_model('models/classification_AGN_galaxy_may_15_2022')\n",
    "    radio_det_clf   = pyc.load_model('models/classification_radio_detect_may_16_2022')\n",
    "    redshift_reg    = pyr.load_model('models/regression_z_may_17_2022')  # to use on full sample\n",
    "    if use_second_z_model:\n",
    "        redshift_reg_2  = pyr.load_model('models/regression_z_may_18_2022')  # to use on sources with predicted z >= 2\n",
    "    if use_third_z_model:\n",
    "        redshift_reg_3  = pyr.load_model('models/regression_z_may_30_2022')  # to use on sources with predicted z >= 3\n",
    "    if use_fourth_z_model:\n",
    "        # redshift_reg_4  = pyr.load_model('models/regression_z_may_31_2022')  # to use on sources with predicted z >= 3.7 (for z >= 4, regression_z_may_31_4_2022)\n",
    "        # redshift_reg_4  = pyr.load_model('models/regression_z_may_31_4_2022')  # to use on sources with predicted z >= 3.7 (for z >= 4, regression_z_may_31_4_2022)\n",
    "        # redshift_reg_4  = pyr.load_model('models/regression_z_jun_01_2022')  # to use on sources with predicted z >= 3.7 used with SMOGN\n",
    "        redshift_reg_4  = pyr.load_model('models/regression_z_jul_19_2022')  # to use on sources with predicted z >= 3.6 used with SMOGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_zeroth_model:\n",
    "    threshold_star = 0.37441  # 0.5, 0.15688 from ROC AUC in train+test, 0.37441 from PR curve\n",
    "threshold_AGN   = 0.31117  # 0.5, 0.3094 from ROC AUC in train+test, 0.31117 from PR curve\n",
    "threshold_radio = 4.99972232e-01  # 0.5, 4.99972232e-01 from ROC AUC in train+test and PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_zeroth_model:  # we want no-star sources => label == 0\n",
    "    full_catalog_df = predict_star(full_catalog_df, star_clf, threshold_star)\n",
    "    unknown_cat_df  = predict_star(unknown_cat_df,  star_clf, threshold_star)\n",
    "elif not use_zeroth_model:\n",
    "    full_catalog_df['pred_star']     = 0\n",
    "    full_catalog_df['Score_no_star'] = 1\n",
    "    unknown_cat_df['pred_star']      = 0\n",
    "    unknown_cat_df['Score_no_star']  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = predict_AGN_gal(full_catalog_df, AGN_gal_clf, threshold_AGN)\n",
    "unknown_cat_df  = predict_AGN_gal(unknown_cat_df,  AGN_gal_clf, threshold_AGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = predict_radio_det(full_catalog_df, radio_det_clf, threshold_radio)\n",
    "unknown_cat_df  = predict_radio_det(unknown_cat_df,  radio_det_clf, threshold_radio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = predict_z_full(full_catalog_df, redshift_reg)\n",
    "unknown_cat_df  = predict_z_full(unknown_cat_df,  redshift_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores before applying further z models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_zeroth_model:\n",
    "    temp_filt_pred_nstr    = np.array(full_catalog_df.loc[:, 'pred_star'] == 0)  # filter for not being predicted as a star\n",
    "elif not use_zeroth_model:\n",
    "    temp_filt_pred_nstr    = np.ones_like(full_catalog_df.loc[:, 'class']).astype(bool)\n",
    "temp_filt_pred_rAGN        = np.array(full_catalog_df.loc[:, 'pred_class'] == 1) &\\\n",
    "                             np.array(full_catalog_df.loc[:, 'pred_radio'] == 1) &\\\n",
    "                             temp_filt_pred_nstr\n",
    "sigma_mad_early            = sigma_mad(full_catalog_df.loc[temp_filt_pred_rAGN, 'Z'],    full_catalog_df.loc[temp_filt_pred_rAGN, 'pred_Z'])\n",
    "sigma_nmad_early           = sigma_nmad(full_catalog_df.loc[temp_filt_pred_rAGN, 'Z'],   full_catalog_df.loc[temp_filt_pred_rAGN, 'pred_Z'])\n",
    "sigma_z_early              = sigma_z(full_catalog_df.loc[temp_filt_pred_rAGN, 'Z'],      full_catalog_df.loc[temp_filt_pred_rAGN, 'pred_Z'])\n",
    "sigma_z_norm_early         = sigma_z_norm(full_catalog_df.loc[temp_filt_pred_rAGN, 'Z'], full_catalog_df.loc[temp_filt_pred_rAGN, 'pred_Z'])\n",
    "out_frac_early             = outlier_frac(full_catalog_df.loc[temp_filt_pred_rAGN, 'Z'], full_catalog_df.loc[temp_filt_pred_rAGN, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_z_limit               = 3.6\n",
    "temp_filt_high_z_rAGN      = temp_filt_pred_rAGN * (full_catalog_df.loc[:, 'pred_Z'] >= temp_z_limit)\n",
    "sigma_mad_early_hiz        = sigma_mad(full_catalog_df.loc[temp_filt_high_z_rAGN, 'Z'],    full_catalog_df.loc[temp_filt_high_z_rAGN, 'pred_Z'])\n",
    "sigma_nmad_early_hiz       = sigma_nmad(full_catalog_df.loc[temp_filt_high_z_rAGN, 'Z'],   full_catalog_df.loc[temp_filt_high_z_rAGN, 'pred_Z'])\n",
    "sigma_z_early_hiz          = sigma_z(full_catalog_df.loc[temp_filt_high_z_rAGN, 'Z'],      full_catalog_df.loc[temp_filt_high_z_rAGN, 'pred_Z'])\n",
    "sigma_z_norm_early_hiz     = sigma_z_norm(full_catalog_df.loc[temp_filt_high_z_rAGN, 'Z'], full_catalog_df.loc[temp_filt_high_z_rAGN, 'pred_Z'])\n",
    "out_frac_early_hiz         = outlier_frac(full_catalog_df.loc[temp_filt_high_z_rAGN, 'Z'], full_catalog_df.loc[temp_filt_high_z_rAGN, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_lim_a    = 2.0\n",
    "redshift_tol_a    = 0.0\n",
    "redshift_lim_b    = 3.0\n",
    "redshift_tol_b    = 0.0\n",
    "redshift_lim_c    = 3.6  # 3.6, 3.7, 4.0\n",
    "redshift_tol_c    = 0.0\n",
    "if use_second_z_model:\n",
    "    full_catalog_df = predict_z_high(full_catalog_df, redshift_reg_2, redshift_lim_a, redshift_tol_a)\n",
    "    unknown_cat_df  = predict_z_high(unknown_cat_df,  redshift_reg_2, redshift_lim_a, redshift_tol_a)\n",
    "if use_third_z_model:\n",
    "    full_catalog_df = predict_z_high(full_catalog_df, redshift_reg_3, redshift_lim_b, redshift_tol_b)\n",
    "    unknown_cat_df  = predict_z_high(unknown_cat_df,  redshift_reg_3, redshift_lim_b, redshift_tol_b)\n",
    "if use_fourth_z_model:\n",
    "    full_catalog_df = predict_z_high(full_catalog_df, redshift_reg_4, redshift_lim_c, redshift_tol_c)\n",
    "    unknown_cat_df  = predict_z_high(unknown_cat_df,  redshift_reg_4, redshift_lim_c, redshift_tol_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111, projection='scatter_density', xscale='log', yscale='log')\n",
    "plot_redshift_compare(full_catalog_df.loc[:, 'Z'], full_catalog_df.loc[:, 'pred_Z'], ax_pre=ax1, title=None, dpi=10, show_clb=True, log_stretch=False)\n",
    "ax1.axvline(x=(1 + redshift_lim_a), ls='--', c='k', lw=2.5)\n",
    "ax1.axhline(y=(1 + redshift_lim_a), ls='--', c='k', lw=2.5)\n",
    "ax1.axvline(x=(1 + redshift_lim_c), ls='--', c='k', lw=2.5)\n",
    "ax1.axhline(y=(1 + redshift_lim_c), ls='--', c='k', lw=2.5)\n",
    "if use_second_z_model or use_third_z_model or use_fourth_z_model:\n",
    "    ax1.set_ylabel('$1 + z_{\\mathrm{Predicted}}^{\\mathrm{combined\\,models}}$', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histogram to compare redshift predictions in after all models passings (on HETDEX validation data only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if used_area == 'HETDEX':\n",
    "    if HETDEX_subset == 'Full':\n",
    "        filter_rAGN_t_H   = (full_catalog_df.loc[:, 'radio_AGN'] == 1)\n",
    "        filter_redshift_H = (full_catalog_df.loc[:, 'Z'] > 0)\n",
    "        full_catalog_H_df = full_catalog_df.loc[filter_rAGN_t_H & filter_redshift_H]\n",
    "        \n",
    "        train_test_H_df   = full_catalog_H_df.loc[np.isfinite(full_catalog_H_df.loc[:, 'Z'])].sample(frac=0.8, random_state=seed)  # Train + test sets\n",
    "        validation_H_df   = full_catalog_H_df.drop(train_test_H_df.index)  # Validation data\n",
    "        \n",
    "        filter_rAGN_t_v_H = (full_catalog_df.loc[:, 'radio_AGN'] == 1)\n",
    "        filt_rAGN_p_H     = (validation_H_df.loc[:, 'pred_class'] == 1) & (validation_H_df.loc[:, 'pred_radio'] == 1)\n",
    "        filt_new_rAGN_p_H = filt_rAGN_p_H & np.array(validation_H_df.loc[:, 'radio_AGN'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if used_area == 'HETDEX':\n",
    "    if HETDEX_subset == 'Full':\n",
    "        fig             = plt.figure(figsize=(10,3.5))\n",
    "        ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "        \n",
    "        min_for_range = np.nanmin([np.nanmin(validation_H_df.loc[:, 'Z']),\\\n",
    "                                   np.nanmin(validation_H_df.loc[:, 'pred_Z'])])\n",
    "        max_for_range = np.nanmax([np.nanmax(validation_H_df.loc[:, 'Z']),\\\n",
    "                                   np.nanmax(validation_H_df.loc[:, 'pred_Z'])])\n",
    "        bins_z        = np.linspace(min_for_range, max_for_range, 70)\n",
    "        \n",
    "        \n",
    "        \n",
    "        _, bins, _ = ax1.hist(validation_H_df.loc[:, 'pred_Z'], bins=bins_z, histtype='stepfilled',\\\n",
    "                              ec='k', fc='mediumpurple', lw=3.5,\\\n",
    "                              label=f\"Predicted\\nN={np.sum(np.isfinite(validation_H_df.loc[:, 'pred_Z'])):,}\")\n",
    "        ax1.hist(validation_H_df.loc[:, 'Z'], bins=bins_z, histtype='stepfilled', ec='k',\\\n",
    "                 fc='darkcyan', lw=3.5, label=f\"True\\nN={np.sum(np.sum(np.isfinite(validation_H_df.loc[:, 'Z']))):,}\", alpha=0.7)\n",
    "        \n",
    "        # ax1.axvline(x=3.7, ls='--', c='k', lw=2.5, zorder=10)\n",
    "        # ax1.axvline(x=3.8, ls='--', c='k', lw=2.5, zorder=10)\n",
    "        # ax1.axvline(x=3.9, ls='--', c='k', lw=2.5, zorder=10)\n",
    "        \n",
    "        ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax1.tick_params(which='major', length=8, width=1.5)\n",
    "        ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "        # ax1.set_xlabel('$m_{\\mathrm{W1}}\\, \\mathrm{[AB]}$', size=20)\n",
    "        ax1.set_xlabel('$z_{\\mathrm{AGN}}$', size=20)\n",
    "        ax1.set_ylabel('Frequency', size=20)\n",
    "        # ax1.set_ylabel('Frequency', size=20)\n",
    "        plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "        plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "        plt.legend(loc=1, fontsize=16)\n",
    "        # ax1.invert_xaxis()\n",
    "        # ax1.set_xlim(left=-4, right=6)\n",
    "        #ax1.set_aspect('equal', 'box')\n",
    "        ax1.set_title(used_area, fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        if save_plot_flag:\n",
    "            plt.savefig(f'plots/hist_true_predicted_z_{used_area}_validation.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional columns with radio AGN prediction as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['pred_radio_AGN']     = np.array(full_catalog_df.loc[:, 'pred_star']  == 0) &\\\n",
    "                                        np.array(full_catalog_df.loc[:, 'pred_class'] == 1) &\\\n",
    "                                        np.array(full_catalog_df.loc[:, 'pred_radio'] == 1)\n",
    "full_catalog_df['Score_rAGN']         = full_catalog_df.loc[:, 'Score_no_star'] *\\\n",
    "                                        full_catalog_df.loc[:, 'Score_AGN'] *\\\n",
    "                                        full_catalog_df.loc[:, 'Score_radio']\n",
    "rad_score_scaler                      = MinMaxScaler()\n",
    "rad_score_scaler.fit(ull_catalog_df.loc[:, 'Score_radio'].values.reshape(-1, 1))\n",
    "full_catalog_df['scaled_score_radio'] = rad_score_scaler.transform(full_catalog_df.loc[:, 'Score_radio'].values.reshape(-1, 1))\n",
    "full_catalog_df['scaled_score_rAGN']  = full_catalog_df.loc[:, 'Score_AGN'] * full_catalog_df.loc[:, 'scaled_score_radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_cat_df['pred_radio_AGN']     = np.array(unknown_cat_df.loc[:, 'pred_star']  == 0) &\\\n",
    "                                       np.array(unknown_cat_df.loc[:, 'pred_class'] == 1) &\\\n",
    "                                       np.array(unknown_cat_df.loc[:, 'pred_radio'] == 1)\n",
    "unknown_cat_df['Score_rAGN']         = unknown_cat_df.loc[:, 'Score_no_star'] *\\\n",
    "                                       unknown_cat_df.loc[:, 'Score_AGN'] *\\\n",
    "                                       unknown_cat_df.loc[:, 'Score_radio']\n",
    "\n",
    "unknown_cat_df['scaled_score_radio'] = rad_score_scaler.transform(unknown_cat_df.loc[:, 'Score_radio'].values.reshape(-1, 1))\n",
    "unknown_cat_df['scaled_score_rAGN']  = unknown_cat_df.loc[:, 'Score_AGN'] * unknown_cat_df.loc[:, 'scaled_score_radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_cols = ['is_str', 'pred_star', 'class', 'pred_class', 'radio_detect', 'pred_radio', 'Z', 'pred_Z']\n",
    "if not use_zeroth_model:\n",
    "    displayed_cols.remove('is_str')\n",
    "    displayed_cols.remove('pred_star')\n",
    "full_catalog_df.loc[:, displayed_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Include AGN detection criteria from literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = add_AGN_criteria(full_catalog_df)\n",
    "unknown_cat_df  = add_AGN_criteria(unknown_cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain intermediate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_radio_AGN_t      = np.array(full_catalog_df.loc[:, 'class'] == 1) & np.array(full_catalog_df.loc[:, 'radio_detect'] == 1)\n",
    "if use_zeroth_model:\n",
    "    filter_known_spec = (full_catalog_df.loc[:, 'class'] == 0) |\\\n",
    "                        (full_catalog_df.loc[:, 'class'] == 1) |\\\n",
    "                        (full_catalog_df.loc[:, 'class'] == 2)\n",
    "elif not use_zeroth_model:\n",
    "    filter_known_spec = (full_catalog_df.loc[:, 'class'] == 0) |\\\n",
    "                        (full_catalog_df.loc[:, 'class'] == 1)\n",
    "total_size              = len(full_catalog_df)\n",
    "filter_AGN_t            = np.array(full_catalog_df.loc[:, 'class'] == 1)\n",
    "num_str_t               = np.sum(np.array(full_catalog_df.loc[:, 'class'] == 2))\n",
    "num_AGN_t               = np.sum(filter_AGN_t)\n",
    "num_gal_t               = np.sum(np.array(full_catalog_df.loc[:, 'class'] == 0))\n",
    "num_str_t               = np.sum(np.array(full_catalog_df.loc[:, 'is_str'] == 1))\n",
    "num_radio_t             = np.sum(np.array(full_catalog_df.loc[:, 'radio_detect'] == 1))\n",
    "num_radio_AGN_t         = np.sum(filter_radio_AGN_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_radio_AGN_p      = np.array(full_catalog_df.loc[:, 'Score_AGN']          >= threshold_AGN) &\\\n",
    "#                             np.array(full_catalog_df.loc[:, 'Score_radio']      >= threshold_radio)\n",
    "if use_zeroth_model:\n",
    "    filter_non_str_p      = np.array(full_catalog_df.loc[:, 'pred_star'] == 0)\n",
    "elif not use_zeroth_model:\n",
    "    filter_non_str_p      = np.ones_like(full_catalog_df.loc[:, 'class']).astype(bool)\n",
    "filter_radio_AGN_p        = full_catalog_df['pred_radio_AGN']\n",
    "filt_hiz_rAGN_p           = filter_radio_AGN_p * np.array(full_catalog_df.loc[:, 'pred_Z'] >= redshift_lim_c)\n",
    "filter_AGN_p              = np.array(full_catalog_df.loc[:, 'pred_class'] == 1) & filter_non_str_p\n",
    "filter_radio_p            = np.array(full_catalog_df.loc[:, 'pred_radio'] == 1)\n",
    "filt_new_rAGN_p           = filter_radio_AGN_p & np.array(full_catalog_df.loc[:, 'radio_AGN'] == 0)\n",
    "num_AGN_p                 = np.sum(filter_AGN_p)\n",
    "num_gal_p                 = np.sum(np.array(full_catalog_df.loc[:, 'pred_class'] == 0) & filter_non_str_p)\n",
    "num_radio_p               = np.sum(filter_radio_p)\n",
    "num_radio_AGN_p           = np.sum(filter_radio_AGN_p)\n",
    "num_rAGN_MQC_p            = np.sum(filter_radio_AGN_p & np.array(full_catalog_df.loc[:, 'class'] == 1))\n",
    "num_rAGN_gal_p            = np.sum(filter_radio_AGN_p & np.array(full_catalog_df.loc[:, 'class'] == 0))\n",
    "num_rAGN_str_p            = np.sum(filter_radio_AGN_p & np.array(full_catalog_df.loc[:, 'is_str'] == 1))\n",
    "num_rAGN_rad_p            = np.sum(filter_radio_AGN_p & np.array(full_catalog_df.loc[:, 'radio_detect'] == 1))\n",
    "num_new_rAGN_p            = np.sum(filter_radio_AGN_p) - np.sum(filter_radio_AGN_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for Star/not-star classification on confirmed sources (AGN + Galaxies + Stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_zeroth_model:\n",
    "    cm_str = np.array([[np.sum(np.array(full_catalog_df.loc[:, 'is_str'] == 0) & np.array(full_catalog_df.loc[:, 'pred_star'] == 0)),\\\n",
    "                        np.sum(np.array(full_catalog_df.loc[:, 'is_str'] == 0) & np.array(full_catalog_df.loc[:, 'pred_star'] == 1))],\\\n",
    "                       [np.sum(np.array(full_catalog_df.loc[:, 'is_str'] == 1) & np.array(full_catalog_df.loc[:, 'pred_star'] == 0)),\\\n",
    "                        np.sum(np.array(full_catalog_df.loc[:, 'is_str'] == 1) & np.array(full_catalog_df.loc[:, 'pred_star'] == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for AGN prediction on confirmed sources (AGN/galaxies). Including initial prediction of not being star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_filt_AGN = filter_non_str_p * filter_known_spec\n",
    "cm_AGN = np.array([[np.sum(np.array(full_catalog_df.loc[tmp_filt_AGN, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_AGN, 'pred_class'] == 0)),\\\n",
    "                    np.sum(np.array(full_catalog_df.loc[tmp_filt_AGN, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_AGN, 'pred_class'] == 1))],\\\n",
    "                   [np.sum(np.array(full_catalog_df.loc[tmp_filt_AGN, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_AGN, 'pred_class'] == 0)),\\\n",
    "                    np.sum(np.array(full_catalog_df.loc[tmp_filt_AGN, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_AGN, 'pred_class'] == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for AGN prediction on all sources (AGN/galaxies + unknown [stars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm_AGN_large = np.array([[np.sum(np.array(full_catalog_df.loc[:, 'class'] == 0)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 0) & filter_non_str_p),\\\n",
    "#                           np.sum(np.array(full_catalog_df.loc[:, 'class'] == 0)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 0.5)),\\\n",
    "#                           np.sum(np.array(full_catalog_df.loc[:, 'class'] == 0)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 1) & filter_non_str_p)],\\\n",
    "#                          [np.sum((np.array(full_catalog_df.loc[:, 'class'] == 0.5) | np.array(full_catalog_df.loc[:, 'class'] == 2) | ~filter_non_str_p)     & np.array(full_catalog_df.loc[:, 'pred_class'] == 0)),\\\n",
    "#                           np.sum((np.array(full_catalog_df.loc[:, 'class'] == 0.5) | np.array(full_catalog_df.loc[:, 'class'] == 2) | ~filter_non_str_p)     & np.array(full_catalog_df.loc[:, 'pred_class'] == 0.5)),\\\n",
    "#                           np.sum((np.array(full_catalog_df.loc[:, 'class'] == 0.5) | np.array(full_catalog_df.loc[:, 'class'] == 2) | ~filter_non_str_p)     & np.array(full_catalog_df.loc[:, 'pred_class'] == 1))],\\\n",
    "#                          [np.sum(np.array(full_catalog_df.loc[:, 'class'] == 1)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 0) & filter_non_str_p),\\\n",
    "#                           np.sum(np.array(full_catalog_df.loc[:, 'class'] == 1)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 0.5)),\\\n",
    "#                           np.sum(np.array(full_catalog_df.loc[:, 'class'] == 1)    & np.array(full_catalog_df.loc[:, 'pred_class'] == 1) & filter_non_str_p)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices from literature AGN criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_filt_sp_nostr = filter_known_spec * filter_non_str_p\n",
    "cm_AGN_S12 = np.array([[np.sum(np.array(full_catalog_df.loc[filter_non_str_p, 'class'] == 0) & np.array(full_catalog_df.loc[filter_non_str_p, 'S12_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[filter_non_str_p, 'class'] == 0) & np.array(full_catalog_df.loc[filter_non_str_p, 'S12_AGN'] == 1))],\\\n",
    "            [np.sum(np.array(full_catalog_df.loc[filter_non_str_p, 'class'] == 1) & np.array(full_catalog_df.loc[filter_non_str_p, 'S12_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[filter_non_str_p, 'class'] == 1) & np.array(full_catalog_df.loc[filter_non_str_p, 'S12_AGN'] == 1))]])\n",
    "\n",
    "cm_AGN_M12 = np.array([[np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M12_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M12_AGN'] == 1))],\\\n",
    "            [np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M12_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M12_AGN'] == 1))]])\n",
    "\n",
    "cm_AGN_M16 = np.array([[np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M16_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M16_AGN'] == 1))],\\\n",
    "            [np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M16_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'M16_AGN'] == 1))]])\n",
    "\n",
    "cm_AGN_B18 = np.array([[np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'B18_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 0) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'B18_AGN'] == 1))],\\\n",
    "            [np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'B18_AGN'] == 0)),\\\n",
    "             np.sum(np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'class'] == 1) & np.array(full_catalog_df.loc[tmp_filt_sp_nostr, 'B18_AGN'] == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio detection prediction on all sources (AGN/galaxies + unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm_radio = np.array([[np.sum(np.array(full_catalog_df.loc[filter_AGN_p, 'radio_detect'] == 0) &\\\n",
    "#                              np.array(full_catalog_df.loc[filter_AGN_p, 'pred_radio']   == 0)),\\\n",
    "#                       np.sum(np.array(full_catalog_df.loc[filter_AGN_p, 'radio_detect'] == 0) &\\\n",
    "#                              np.array(full_catalog_df.loc[filter_AGN_p, 'pred_radio']   == 1))],\\\n",
    "#                      [np.sum(np.array(full_catalog_df.loc[filter_AGN_p, 'radio_detect'] == 1) &\\\n",
    "#                              np.array(full_catalog_df.loc[filter_AGN_p, 'pred_radio']   == 0)),\\\n",
    "#                       np.sum(np.array(full_catalog_df.loc[filter_AGN_p, 'radio_detect'] == 1) &\\\n",
    "#                              np.array(full_catalog_df.loc[filter_AGN_p, 'pred_radio']   == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio detection prediction on confirmed sources (AGN/galaxies/stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_radio_conf = np.array([[np.sum(np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'radio_detect'] == 0) &\\\n",
    "                                  np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'pred_radio']   == 0)),\\\n",
    "                           np.sum(np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'radio_detect'] == 0) &\\\n",
    "                                  np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'pred_radio']   == 1))],\\\n",
    "                          [np.sum(np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'radio_detect'] == 1) &\\\n",
    "                                  np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'pred_radio']   == 0)),\\\n",
    "                           np.sum(np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'radio_detect'] == 1) &\\\n",
    "                                  np.array(full_catalog_df.loc[filter_AGN_p & filter_known_spec, 'pred_radio']   == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio AGN prediction on all sources (AGN/galaxies + unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_radio_AGN = np.array([[np.sum(np.array(full_catalog_df['radio_AGN'] == 0) & np.array(full_catalog_df['pred_radio_AGN'] == 0)),\\\n",
    "#                           np.sum(np.array(full_catalog_df['radio_AGN'] == 0) & np.array(full_catalog_df['pred_radio_AGN'] == 1))],\\\n",
    "#                          [np.sum(np.array(full_catalog_df['radio_AGN'] == 1) & np.array(full_catalog_df['pred_radio_AGN'] == 0)),\\\n",
    "#                           np.sum(np.array(full_catalog_df['radio_AGN'] == 1) & np.array(full_catalog_df['pred_radio_AGN'] == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio AGN prediction on confirmed sources (AGN/galaxies/stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_radio_AGN_conf = np.array([[np.sum(np.array(full_catalog_df.loc[filter_known_spec, 'radio_AGN'] == 0) &\\\n",
    "                                      np.array(full_catalog_df.loc[filter_known_spec,'pred_radio_AGN'] == 0)),\\\n",
    "                               np.sum(np.array(full_catalog_df.loc[filter_known_spec, 'radio_AGN'] == 0) &\\\n",
    "                                      np.array(full_catalog_df.loc[filter_known_spec,'pred_radio_AGN'] == 1))],\\\n",
    "                              [np.sum(np.array(full_catalog_df.loc[filter_known_spec, 'radio_AGN'] == 1) &\\\n",
    "                                      np.array(full_catalog_df.loc[filter_known_spec,'pred_radio_AGN'] == 0)),\\\n",
    "                               np.sum(np.array(full_catalog_df.loc[filter_known_spec, 'radio_AGN'] == 1) &\\\n",
    "                                      np.array(full_catalog_df.loc[filter_known_spec,'pred_radio_AGN'] == 1))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics from redshift predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sigma_mad_field            = sigma_mad(full_catalog_df.loc[filter_radio_AGN_p, 'Z'],    full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'])\n",
    "sigma_nmad_field           = sigma_nmad(full_catalog_df.loc[filter_radio_AGN_p, 'Z'],   full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'])\n",
    "sigma_z_field              = sigma_z(full_catalog_df.loc[filter_radio_AGN_p, 'Z'],      full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'])\n",
    "sigma_z_norm_field         = sigma_z_norm(full_catalog_df.loc[filter_radio_AGN_p, 'Z'], full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'])\n",
    "out_frac_field             = outlier_frac(full_catalog_df.loc[filter_radio_AGN_p, 'Z'], full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_z_limit               = 3.6\n",
    "filt_high_z_rAGN_p         = filter_radio_AGN_p * (full_catalog_df.loc[:, 'pred_Z'] >= temp_z_limit)\n",
    "sigma_mad_field_hiz        = sigma_mad(full_catalog_df.loc[filt_high_z_rAGN_p, 'Z'],    full_catalog_df.loc[filt_high_z_rAGN_p, 'pred_Z'])\n",
    "sigma_nmad_field_hiz       = sigma_nmad(full_catalog_df.loc[filt_high_z_rAGN_p, 'Z'],   full_catalog_df.loc[filt_high_z_rAGN_p, 'pred_Z'])\n",
    "sigma_z_field_hiz          = sigma_z(full_catalog_df.loc[filt_high_z_rAGN_p, 'Z'],      full_catalog_df.loc[filt_high_z_rAGN_p, 'pred_Z'])\n",
    "sigma_z_norm_field_hiz     = sigma_z_norm(full_catalog_df.loc[filt_high_z_rAGN_p, 'Z'], full_catalog_df.loc[filt_high_z_rAGN_p, 'pred_Z'])\n",
    "out_frac_field_hiz         = outlier_frac(full_catalog_df.loc[filt_high_z_rAGN_p, 'Z'], full_catalog_df.loc[filt_high_z_rAGN_p, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms for scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score  = np.nanmin(full_catalog_df.loc[:, 'Score_AGN'])\n",
    "max_score  = np.nanmax(full_catalog_df.loc[:, 'Score_AGN'])\n",
    "score_bins = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size = np.sum(np.isfinite(full_catalog_df.loc[:, 'Score_AGN']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[:, 'Score_AGN'], bins=score_bins, histtype='stepfilled', ec='k',\\\n",
    "         lw=3.5, color=cm.get_cmap('cet_gray')(0.8), alpha=1.0, label=f'{used_area} known sources\\nN={sample_size:,}')\n",
    "\n",
    "ax1.axvline(x=0.5, ls='--', c='k', lw=2.5)\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('AGN/Galaxy class score', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_AGN_scores_known_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score  = np.nanmin(unknown_cat_df.loc[:, 'Score_AGN'])\n",
    "max_score  = np.nanmax(unknown_cat_df.loc[:, 'Score_AGN'])\n",
    "score_bins = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size = np.sum(np.isfinite(unknown_cat_df.loc[:, 'Score_AGN']))\n",
    "\n",
    "ax1.hist(unknown_cat_df.loc[:, 'Score_AGN'], bins=score_bins, histtype='stepfilled', ec='k',\\\n",
    "         lw=3.5, color=cm.get_cmap('cet_gray')(0.8), alpha=1.0, label=f'{used_area} unknown sources\\nN={sample_size:,}')\n",
    "\n",
    "ax1.axvline(x=0.5, ls='--', c='k', lw=2.5)\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('AGN/Galaxy class score', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_AGN_scores_unknown_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'Score_radio'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'Score_radio'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'Score_radio']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'Score_radio']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'Score_radio'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'True class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'Score_radio'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'True class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "\n",
    "ax1.axvline(x=0.5, ls='--', c='k', lw=2.5, zorder=10)\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Radio detection score', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "fig.tight_layout()\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_radio_scores_true_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'Score_radio'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'Score_radio'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] < threshold_AGN), 'Score_radio']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'Score_radio']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] < threshold_AGN), 'Score_radio'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'Predicted class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'Score_radio'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'Predicted class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "\n",
    "ax1.axvline(x=0.5, ls='--', c='k', lw=2.5, zorder=9)\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Radio detection score', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_radio_scores_predicted_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms for predicted and original redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'Z'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'Z'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'Z']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'Z']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'Z'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'True class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'Z'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'True class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Original redshift', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_original_redshift_true_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'Z'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'Z'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] <  threshold_AGN), 'Z']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'Z']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] < threshold_AGN), 'Z'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'Predicted class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'Z'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'Predicted class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Original redshift', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_true_redshift_predicted_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'pred_Z'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'pred_Z'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'pred_Z']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'pred_Z']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 0), 'pred_Z'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'True class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'class'] == 1), 'pred_Z'], bins=score_bins,\\\n",
    "         histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'True class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Predicted redshift', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_redshift_true_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,5.0))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_score       = np.nanmin(full_catalog_df.loc[:, 'pred_Z'])\n",
    "max_score       = np.nanmax(full_catalog_df.loc[:, 'pred_Z'])\n",
    "score_bins      = np.linspace(min_score, max_score, 30)\n",
    "\n",
    "sample_size_gal = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] < threshold_AGN), 'pred_Z']))\n",
    "sample_size_AGN = np.sum(np.isfinite(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'pred_Z']))\n",
    "\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] < threshold_AGN), 'pred_Z'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.9,\\\n",
    "         label=f'Predicted class: Galaxy\\nN={sample_size_gal:,}', zorder=np.ceil((sample_size_AGN/sample_size_gal)))\n",
    "ax1.hist(full_catalog_df.loc[np.array(full_catalog_df.loc[:, 'Score_AGN'] >= threshold_AGN), 'pred_Z'],\\\n",
    "         bins=score_bins, histtype='stepfilled', ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.7), alpha=0.9,\\\n",
    "         label=f'Predicted class: AGN\\nN={sample_size_AGN:,}', zorder=np.ceil((sample_size_gal/sample_size_AGN)))\n",
    "    \n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "ax1.set_xlabel('Predicted redshift', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=14)\n",
    "plt.grid(False)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_predicted_redshift_predicted_class_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select sources predicted to be Radio AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayed_cols = ['is_str', 'pred_star', 'class', 'pred_class', 'radio_detect', 'pred_radio', 'Z', 'pred_Z']\n",
    "if not use_zeroth_model:\n",
    "    displayed_cols.remove('is_str')\n",
    "    displayed_cols.remove('pred_star')\n",
    "full_catalog_df.loc[filter_radio_AGN_p, displayed_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add individual metrics for redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_catalog_df['Delta_z_N'] = np.around((full_catalog_df.loc[:, 'pred_Z'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)\n",
    "\n",
    "full_catalog_df['sigma_NMAD'] = np.around(1.48 * np.abs(full_catalog_df.loc[:, 'pred_Z'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_0_t    = f'Out of {total_size:,} initial sources in {used_area},\\n'\n",
    "str_1_t    = f'{num_gal_t:,} are confirmed to be galaxies. On the other side,\\n'\n",
    "str_2_t    = f'{num_str_t:,} are listed as SDSS-DR16 stars and {num_AGN_t:,} are MQC AGN.\\n'\n",
    "str_3_t    = f'Also, {num_radio_AGN_t:,} AGN are detected in radio.'\n",
    "\n",
    "str_0_p    = f'Out of {num_radio_AGN_t:,} initial radio-detected AGN in {used_area},\\n'\n",
    "str_1_p    = f'{num_gal_p:,} are predicted to be galaxies. On the other side,\\n'\n",
    "str_2_p    = f'{num_AGN_p:,} are predicted to be AGN. From the predicted AGN,\\n'\n",
    "str_3_p    = f'{num_radio_AGN_p:,} are predicted to be detected in radio.'\n",
    "\n",
    "str_0_rAGN = f'{num_radio_AGN_p:,} sources were predicted to be Radio AGN in {used_area}.\\n'\n",
    "str_1_rAGN = f'{num_rAGN_MQC_p:,} of them were listed in MQC.\\n'\n",
    "str_2_rAGN = f'{num_rAGN_gal_p:,} of them are listed as SDSS-DR16 galaxies.\\n'\n",
    "str_3_rAGN = f'{num_rAGN_str_p:,} of them are listed as SDSS-DR16 stars.\\n'\n",
    "str_4_rAGN = f'{num_rAGN_rad_p:,} of them have radio detections.\\n'\n",
    "str_5_rAGN = f'Thus, {num_new_rAGN_p:,} sources are new radio AGN.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('-' * 60)\n",
    "print(str_0_t + str_1_t + str_2_t + str_3_t)\n",
    "print('-' * 60)\n",
    "print(str_0_p + str_1_p + str_2_p + str_3_p)\n",
    "print('-' * 60)\n",
    "print(str_0_rAGN + str_1_rAGN + str_2_rAGN + str_3_rAGN + str_4_rAGN + str_5_rAGN)\n",
    "print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_columns = ['Name', 'RA_ICRS', 'DE_ICRS', 'TYPE', 'band_num', 'class', 'pred_class', 'Score_AGN',\\\n",
    "                'radio_detect', 'pred_radio', 'scaled_score_radio', 'scaled_score_rAGN', 'Z', 'pred_Z']\n",
    "\n",
    "cols_4_table = ['RA_ICRS', 'DE_ICRS', 'band_num', 'class', 'pred_class', 'Score_AGN', 'radio_detect', 'pred_radio', 'Score_radio', 'Score_rAGN', 'Z', 'pred_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_4_export_S82    = ['Total_flux_VLASS', 'Fint_VLAS82', 'Stotal_TGSS', 'FEP']\n",
    "cols_4_export_HETDEX = ['Total_flux_VLASS', 'Sint_LOFAR', 'Stotal_TGSS', 'FEP', 'TotalFlux_LoLSS']\n",
    "cols_4_export_COSMOS = ['Total_flux_VLASS', 'Stotal_TGSS', 'FEP', 'Flux_COSMOSVLA3']\n",
    "\n",
    "cols_4_exp_all       = {'S82': cols_4_export_S82, 'HETDEX': cols_4_export_HETDEX, 'COSMOS': cols_4_export_COSMOS}\n",
    "\n",
    "cols_photo           = ['W1mproPM', 'W2mproPM', 'gmag', 'rmag', 'imag', 'zmag', 'ymag', 'FUVmag', 'NUVmag',\\\n",
    "                        'Jmag', 'Hmag', 'Kmag', 'W3mag', 'W4mag']\n",
    "\n",
    "cols_4_export        = show_columns + cols_4_exp_all[used_area] + cols_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_high_z   = full_catalog_df.loc[:, 'pred_Z']    >= 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display properties of newly-predicted Radio AGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[filt_new_rAGN_p, cols_4_table].sort_values(by=['pred_Z'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display properties of old Radio AGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[filter_radio_AGN_t, cols_4_table].sort_values(by=['pred_Z'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display properties of old Radio AGN predicted to be Radio AGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[filter_radio_AGN_p * filter_radio_AGN_t, cols_4_table].sort_values(by=['pred_Z'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display properties of all predicted Radio AGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[filt_new_rAGN_p, cols_4_table].sort_values(by=['pred_Z'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for AGN/galaxy prediction on all sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCC_AGN              = MCC_from_CM(cm_AGN)\n",
    "ACC_AGN              = ACC_from_CM(cm_AGN)\n",
    "F1_AGN               = F1_from_CM(cm_AGN)\n",
    "Recall_AGN           = Recall_from_CM(cm_AGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices for AGN criteria from literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MCC_AGN_S12          = MCC_from_CM(cm_AGN_S12)\n",
    "ACC_AGN_S12          = ACC_from_CM(cm_AGN_S12)\n",
    "F1_AGN_S12           = F1_from_CM(cm_AGN_S12)\n",
    "Recall_AGN_S12       = Recall_from_CM(cm_AGN_S12)\n",
    "\n",
    "MCC_AGN_M12          = MCC_from_CM(cm_AGN_M12)\n",
    "ACC_AGN_M12          = ACC_from_CM(cm_AGN_M12)\n",
    "F1_AGN_M12           = F1_from_CM(cm_AGN_M12)\n",
    "Recall_AGN_M12       = Recall_from_CM(cm_AGN_M12)\n",
    "\n",
    "MCC_AGN_M16          = MCC_from_CM(cm_AGN_M16)\n",
    "ACC_AGN_M16          = ACC_from_CM(cm_AGN_M16)\n",
    "F1_AGN_M16           = F1_from_CM(cm_AGN_M16)\n",
    "Recall_AGN_M16       = Recall_from_CM(cm_AGN_M16)\n",
    "\n",
    "MCC_AGN_B18          = MCC_from_CM(cm_AGN_B18)\n",
    "ACC_AGN_B18          = ACC_from_CM(cm_AGN_B18)\n",
    "F1_AGN_B18           = F1_from_CM(cm_AGN_B18)\n",
    "Recall_AGN_B18       = Recall_from_CM(cm_AGN_B18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio detection prediction on all predicted AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCC_radio            = MCC_from_CM(cm_radio)\n",
    "ACC_radio            = ACC_from_CM(cm_radio)\n",
    "F1_radio             = F1_from_CM(cm_radio)\n",
    "Recall_radio         = Recall_from_CM(cm_radio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio detection prediction on all confirmed sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCC_radio_conf       = MCC_from_CM(cm_radio_conf)\n",
    "ACC_radio_conf       = ACC_from_CM(cm_radio_conf)\n",
    "F1_radio_conf        = F1_from_CM(cm_radio_conf)\n",
    "Recall_radio_conf    = Recall_from_CM(cm_radio_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio AGN detection prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCC_radio_AGN        = MCC_from_CM(cm_radio_AGN)\n",
    "ACC_radio_AGN        = ACC_from_CM(cm_radio_AGN)\n",
    "F1_radio_AGN         = F1_from_CM(cm_radio_AGN)\n",
    "Recall_radio_AGN     = Recall_from_CM(cm_radio_AGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for radio AGN detection prediction on confirmed sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCC_radio_AGN_conf    = MCC_from_CM(cm_radio_AGN_conf)\n",
    "ACC_radio_AGN_conf    = ACC_from_CM(cm_radio_AGN_conf)\n",
    "F1_radio_AGN_conf     = F1_from_CM(cm_radio_AGN_conf)\n",
    "Recall_radio_AGN_conf = Recall_from_CM(cm_radio_AGN_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for AGN prediction on all spectroscopically confirmed sources.')\n",
    "print(f'Sample size,                        N = {np.sum(filter_known_spec):,}')\n",
    "print(f'F-1 Score,                         F1 = {F1_AGN:.4f}')\n",
    "print(f'Matthews Correlation Coefficient, MCC = {MCC_AGN:.4f}')\n",
    "print(f'Recall,                        Recall = {Recall_AGN:.4f}')\n",
    "print(f'Accuracy,                         ACC = {ACC_AGN:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for AGN detection criteria (from literature) on all spectroscopically confirmed sources.')\n",
    "print(f'Sample size, N = {np.sum(filter_known_spec):,}')\n",
    "print('Criterion:        S12\\tM12\\tM16\\tB18')\n",
    "print(f'F-1 Score,  F1 = {F1_AGN_S12:.4f}\\t{F1_AGN_M12:.4f}\\t{F1_AGN_M16:.4f}\\t{F1_AGN_B18:.4f}')\n",
    "print(f'MCC,       MCC = {MCC_AGN_S12:.4f}\\t{MCC_AGN_M12:.4f}\\t{MCC_AGN_M16:.4f}\\t{MCC_AGN_B18:.4f}')\n",
    "print(f'Recall, Recall = {Recall_AGN_S12:.4f}\\t{Recall_AGN_M12:.4f}\\t{Recall_AGN_M16:.4f}\\t{Recall_AGN_B18:.4f}')\n",
    "print(f'Accuracy,  ACC = {ACC_AGN_S12:.4f}\\t{ACC_AGN_M12:.4f}\\t{ACC_AGN_M16:.4f}\\t{ACC_AGN_B18:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for radio detection prediction on all predicted AGN')\n",
    "print(f'Sample size,                        N = {np.sum(filter_AGN_p):,}')\n",
    "print(f'F-1 Score,                         F1 = {F1_radio:.4f}')\n",
    "print(f'Matthews Correlation Coefficient, MCC = {MCC_radio:.4f}')\n",
    "print(f'Recall,                        Recall = {Recall_radio:.4f}')\n",
    "print(f'Accuracy,                         ACC = {ACC_radio:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for radio detection prediction on all confirmed sources predicted to be AGN')\n",
    "print(f'Sample size,                        N = {np.sum(filter_AGN_p & filter_known_spec):,}')\n",
    "print(f'F-1 Score,                         F1 = {F1_radio_conf:.4f}')\n",
    "print(f'Matthews Correlation Coefficient, MCC = {MCC_radio_conf:.4f}')\n",
    "print(f'Recall,                        Recall = {Recall_radio_conf:.4f}')\n",
    "print(f'Accuracy,                         ACC = {ACC_radio_conf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for radio AGN detection prediction')\n",
    "print(f'Sample size,                        N = {total_size:,}')\n",
    "print(f'F-1 Score,                         F1 = {F1_radio_AGN:.4f}')\n",
    "print(f'Matthews Correlation Coefficient, MCC = {MCC_radio_AGN:.4f}')\n",
    "print(f'Recall,                        Recall = {Recall_radio_AGN:.4f}')\n",
    "print(f'Accuracy,                         ACC = {ACC_radio_AGN:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for radio AGN detection prediction on all confirmed sources')\n",
    "print(f'Sample size,                        N = {np.sum(filter_known_spec):,}')\n",
    "print(f'F-1 Score,                         F1 = {F1_radio_AGN_conf:.4f}')\n",
    "print(f'Matthews Correlation Coefficient, MCC = {MCC_radio_AGN_conf:.4f}')\n",
    "print(f'Recall,                        Recall = {Recall_radio_AGN_conf:.4f}')\n",
    "print(f'Accuracy,                         ACC = {ACC_radio_AGN_conf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for redshift prediction on all predicted radio AGN with only one Z model')\n",
    "print(f'Sample size,                        N = {np.sum(np.isfinite(full_catalog_df.loc[:, \"Z\"]) & np.isfinite(full_catalog_df.loc[:, \"pred_Z\"])):,}')\n",
    "print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_early:.4f}')\n",
    "print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_early:.4f}')\n",
    "print(f'Sigma z,                          \\u03C3 z = {sigma_z_early:.4f}')\n",
    "print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_early:.4f}')\n",
    "print(f'Outlier fraction,                   \\u03B7 = {out_frac_early:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Metrics for redshift prediction on all predicted radio AGN with all models')\n",
    "print(f'Sample size,                        N = {np.sum(np.isfinite(full_catalog_df.loc[:, \"Z\"]) & np.isfinite(full_catalog_df.loc[:, \"pred_Z\"])):,}')\n",
    "print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_field:.4f}')\n",
    "print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_field:.4f}')\n",
    "print(f'Sigma z,                          \\u03C3 z = {sigma_z_field:.4f}')\n",
    "print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_field:.4f}')\n",
    "print(f'Outlier fraction,                   \\u03B7 = {out_frac_field:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Metrics for redshift prediction on predicted radio AGN with only one Z model at high z (original prediction)')\n",
    "samp_size_tmp  = np.sum(np.isfinite(full_catalog_df.loc[:, \"Z\"]) & np.isfinite(full_catalog_df.loc[:, \"pred_Z\"]) &\\\n",
    "                        np.array(full_catalog_df.loc[:, \"pred_Z\"] >= redshift_lim_c))\n",
    "print(f'Sample size,                        N = {samp_size_tmp:,}')\n",
    "print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_early_hiz:.4f}')\n",
    "print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_early_hiz:.4f}')\n",
    "print(f'Sigma z,                          \\u03C3 z = {sigma_z_early_hiz:.4f}')\n",
    "print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_early_hiz:.4f}')\n",
    "print(f'Outlier fraction,                   \\u03B7 = {out_frac_early_hiz:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('Metrics for redshift prediction on predicted radio AGN with all models at high z')\n",
    "samp_size_tmp  = np.sum(np.isfinite(full_catalog_df.loc[:, \"Z\"]) & np.isfinite(full_catalog_df.loc[:, \"pred_Z\"]) &\\\n",
    "                        np.array(full_catalog_df.loc[:, \"pred_Z\"] >= redshift_lim_c))\n",
    "print(f'Sample size,                        N = {samp_size_tmp:,}')\n",
    "print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_field_hiz:.4f}')\n",
    "print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_field_hiz:.4f}')\n",
    "print(f'Sigma z,                          \\u03C3 z = {sigma_z_field_hiz:.4f}')\n",
    "print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_field_hiz:.4f}')\n",
    "print(f'Outlier fraction,                   \\u03B7 = {out_frac_field_hiz:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_AGN, title=used_area, axin=ax1, display_labels=['Galaxy', 'AGN'], log_stretch=False)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_AGN_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(7,6))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_AGN_large, title=used_area, axin=ax1, display_labels=['Galaxy', 'Unknown', 'AGN'], log_stretch=False)\n",
    "\n",
    "ax1.xaxis.get_label().set_fontsize(18)\n",
    "ax1.yaxis.get_label().set_fontsize(18)\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax1.tick_params(axis='y', which='major', labelrotation=90)\n",
    "plt.yticks(va='center')\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_AGN_all_classes_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_radio, title=used_area, axin=ax1, display_labels=['No\\nRadio', 'Radio'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_radio_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_radio_conf, title=used_area+': confirmed sources', axin=ax1, display_labels=['No\\nRadio', 'Radio'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_radio_confirmed_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_radio_AGN, title=used_area, axin=ax1, display_labels=['No\\nRadio AGN', 'Radio AGN'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_radio_AGN_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6,5))\n",
    "ax1             = fig.add_subplot(111)\n",
    "plot_conf_mat(cm_radio_AGN_conf, title=used_area + ': confirmed sources', axin=ax1, display_labels=['No\\nRadio AGN', 'Radio AGN'], log_stretch=True)\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/conf_matrix_radio_AGN_confirmed_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(6.8,5.3))\n",
    "ax1             = fig.add_subplot(111, projection='scatter_density', xscale='log', yscale='log')\n",
    "plot_redshift_compare(full_catalog_df.loc[filter_radio_AGN_p, 'Z'], full_catalog_df.loc[filter_radio_AGN_p, 'pred_Z'],\\\n",
    "                      ax_pre=ax1, title=None, dpi=10, show_clb=True, log_stretch=False)\n",
    "\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/compare_redshift_{used_area}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig             = plt.figure(figsize=(10,3.5))\n",
    "ax1             = fig.add_subplot(111, xscale='linear', yscale='log')\n",
    "\n",
    "min_for_range = np.nanmin([np.nanmin(full_catalog_df.loc[:, 'Z']),\\\n",
    "                           np.nanmin(full_catalog_df.loc[:, 'pred_Z'])])\n",
    "max_for_range = np.nanmax([np.nanmax(full_catalog_df.loc[:, 'Z']),\\\n",
    "                           np.nanmax(full_catalog_df.loc[:, 'pred_Z'])])\n",
    "bins_z        = np.linspace(min_for_range, max_for_range, 70)\n",
    "\n",
    "\n",
    "\n",
    "_, bins, _ = ax1.hist(full_catalog_df.loc[filt_new_rAGN_p, 'pred_Z'], bins=bins_z, histtype='stepfilled',\\\n",
    "                      ec='k', fc='mediumpurple', lw=3.5,\\\n",
    "                      label=f\"New\\nN={np.sum(filt_new_rAGN_p):,}\")\n",
    "ax1.hist(full_catalog_df.loc[filter_radio_AGN_t * filter_radio_AGN_p, 'Z'], bins=bins_z, histtype='stepfilled', ec='k',\\\n",
    "         fc='darkcyan', lw=3.5, label=f\"True\\nN={np.sum(filter_radio_AGN_t):,}\", alpha=0.7)\n",
    "\n",
    "# ax1.axvline(x=3.6, ls='--', c='k', lw=2.5, zorder=10)\n",
    "# ax1.axvline(x=3.7, ls='--', c='k', lw=2.5, zorder=10)\n",
    "# ax1.axvline(x=3.8, ls='--', c='k', lw=2.5, zorder=10)\n",
    "# ax1.axvline(x=3.9, ls='--', c='k', lw=2.5, zorder=10)\n",
    "# ax1.axvline(x=4.0, ls='--', c='k', lw=2.5, zorder=10)\n",
    "\n",
    "ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax1.tick_params(which='major', length=8, width=1.5)\n",
    "ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "# ax1.set_xlabel('$m_{\\mathrm{W1}}\\, \\mathrm{[AB]}$', size=20)\n",
    "ax1.set_xlabel('$z_{\\mathrm{AGN}}$', size=20)\n",
    "ax1.set_ylabel('Frequency', size=20)\n",
    "# ax1.set_ylabel('Frequency', size=20)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "plt.legend(loc=1, fontsize=16)\n",
    "# ax1.invert_xaxis()\n",
    "# ax1.set_xlim(left=-4, right=6)\n",
    "#ax1.set_aspect('equal', 'box')\n",
    "ax1.set_title(used_area, fontsize=14)\n",
    "fig.tight_layout()\n",
    "if save_plot_flag:\n",
    "    plt.savefig(f'plots/hist_true_predicted_z_{used_area}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional test with data from Ananna et al., 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    full_catalog_A17_df = pd.read_hdf(cat_path + file_S82_Ananna_17, key='df').drop(columns=features_2_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    full_catalog_A17_df = pyr.predict_model(redshift_reg, data=full_catalog_A17_df, round=8)\n",
    "    full_catalog_A17_df = full_catalog_A17_df.rename(columns={'Label': 'pred_Z', 'is_AGN': 'class'})\n",
    "    full_catalog_A17_df['pred_Z'] = np.around(full_catalog_A17_df.loc[:, 'pred_Z'], decimals=6)\n",
    "    redshift_lim_0    = 2.0\n",
    "    redshift_tol_0    = 0.0\n",
    "    redshift_lim_1    = 3.0\n",
    "    redshift_tol_1    = 0.0\n",
    "    redshift_lim_2    = 3.6\n",
    "    redshift_tol_2    = 0.0\n",
    "    if use_second_z_model:\n",
    "        full_catalog_A17_df = pyr.predict_model(redshift_reg_2, data=full_catalog_A17_df, round=8)\n",
    "        filter_pred_z_A17   = full_catalog_A17_df.loc[:, 'pred_Z'] >= (redshift_lim_0 + redshift_tol_0)\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = full_catalog_A17_df.loc[:, 'pred_Z'].mask(filter_pred_z_A17, full_catalog_A17_df.loc[filter_pred_z_A17, 'Label'])\n",
    "        full_catalog_A17_df = full_catalog_A17_df.drop(columns=['Label'])\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = np.around(full_catalog_A17_df.loc[:, 'pred_Z'], decimals=6)\n",
    "    if use_third_z_model:\n",
    "        full_catalog_A17_df = pyr.predict_model(redshift_reg_3, data=full_catalog_A17_df, round=8)\n",
    "        filter_pred_z_A17   = full_catalog_A17_df.loc[:, 'pred_Z'] >= (redshift_lim_1 + redshift_tol_1)\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = full_catalog_A17_df.loc[:, 'pred_Z'].mask(filter_pred_z_A17, full_catalog_A17_df.loc[filter_pred_z_A17, 'Label'])\n",
    "        full_catalog_A17_df = full_catalog_A17_df.drop(columns=['Label'])\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = np.around(full_catalog_A17_df.loc[:, 'pred_Z'], decimals=6)\n",
    "    if use_fourth_z_model:\n",
    "        full_catalog_A17_df = pyr.predict_model(redshift_reg_4, data=full_catalog_A17_df, round=8)\n",
    "        filter_pred_z_A17   = full_catalog_A17_df.loc[:, 'pred_Z'] >= (redshift_lim_2 + redshift_tol_2)\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = full_catalog_A17_df.loc[:, 'pred_Z'].mask(filter_pred_z_A17, full_catalog_A17_df.loc[filter_pred_z_A17, 'Label'])\n",
    "        full_catalog_A17_df = full_catalog_A17_df.drop(columns=['Label'])\n",
    "        full_catalog_A17_df.loc[:, 'pred_Z'] = np.around(full_catalog_A17_df.loc[:, 'pred_Z'], decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    sigma_mad_AGN_A17            = sigma_mad(full_catalog_A17_df.loc[:, 'Z'],    full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_nmad_AGN_A17           = sigma_nmad(full_catalog_A17_df.loc[:, 'Z'],   full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_z_AGN_A17              = sigma_z(full_catalog_A17_df.loc[:, 'Z'],      full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_z_norm_AGN_A17         = sigma_z_norm(full_catalog_A17_df.loc[:, 'Z'], full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    out_frac_AGN_A17             = outlier_frac(full_catalog_A17_df.loc[:, 'Z'], full_catalog_A17_df.loc[:, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    print('Metrics for redshift prediction on AGN from Ananna et al., 2017')\n",
    "    print(f'Sample size,                        N = {np.sum(np.isfinite(full_catalog_A17_df.loc[:, \"zsp\"]) & np.isfinite(full_catalog_A17_df.loc[:, \"pred_Z\"])):,}')\n",
    "    print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_AGN_A17:.4f}')\n",
    "    print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_AGN_A17:.4f}')\n",
    "    print(f'Sigma z,                          \\u03C3 z = {sigma_z_AGN_A17:.4f}')\n",
    "    print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_AGN_A17:.4f}')\n",
    "    print(f'Outlier fraction,                   \\u03B7 = {out_frac_AGN_A17:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    fig              = plt.figure(figsize=(7.5,4.3))\n",
    "    ax1              = fig.add_subplot(111, xscale='linear', yscale='linear')\n",
    "    \n",
    "    min_score        = np.nanmin([np.nanmin(full_catalog_A17_df.loc[:, 'zsp']), np.nanmin(full_catalog_A17_df.loc[:, 'pred_Z'])])\n",
    "    max_score        = np.nanmax([np.nanmax(full_catalog_A17_df.loc[:, 'zsp']), np.nanmax(full_catalog_A17_df.loc[:, 'pred_Z'])])\n",
    "    score_bins       = np.linspace(min_score, max_score, 30)\n",
    "    \n",
    "    sample_size_orig = np.sum(np.isfinite(full_catalog_A17_df.loc[:, 'zsp']))\n",
    "    sample_size_pred = np.sum(np.isfinite(full_catalog_A17_df.loc[:, 'pred_Z']))\n",
    "    \n",
    "    ax1.hist(full_catalog_A17_df.loc[:, 'zsp'], bins=score_bins, histtype='stepfilled',\\\n",
    "             ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.8), alpha=0.9,\\\n",
    "             label=f'Original\\nN={sample_size_orig:,}', zorder=2)\n",
    "    ax1.hist(full_catalog_A17_df.loc[:, 'pred_Z'], bins=score_bins, histtype='stepfilled',\\\n",
    "             ec='k', lw=3.5, color=cm.get_cmap('cet_gray')(0.9), alpha=0.7,\\\n",
    "             label=f'Predicted\\nN={sample_size_pred:,}', zorder=1)\n",
    "        \n",
    "    ax1.tick_params(which='both', top=True, right=True, direction='in')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax1.tick_params(which='major', length=8, width=1.5)\n",
    "    ax1.tick_params(which='minor', length=4, width=1.5)\n",
    "    ax1.set_xlabel('Redshift', size=20)\n",
    "    ax1.set_ylabel('Frequency', size=20)\n",
    "    plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "    plt.setp(ax1.spines.values(), linewidth=3.5)\n",
    "    plt.legend(loc=1, fontsize=14)\n",
    "    plt.grid(False)\n",
    "    ax1.set_title('S82: Ananna+17')\n",
    "    #ax1.set_aspect('equal', 'box')\n",
    "    fig.tight_layout()\n",
    "    if save_plot_flag:\n",
    "        plt.savefig(f'plots/hist_redshift_AGN_{used_area}_Ananna_17.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    full_catalog_A17_df = full_catalog_A17_df.loc[np.array(full_catalog_A17_df.loc[:, 'class'] == 1) &\\\n",
    "                                                  np.array(full_catalog_A17_df.loc[:, 'radio_detect'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    used_z_col = 'zsp'\n",
    "    full_catalog_A17_df['Delta_z_N'] = np.around((full_catalog_A17_df.loc[:, 'pred_Z'] - full_catalog_A17_df.loc[:, used_z_col]) /\\\n",
    "                                                 (1 + full_catalog_A17_df.loc[:, used_z_col]), decimals=3)\n",
    "    full_catalog_A17_df['sigma_NMAD'] = np.around(1.48 * np.abs(full_catalog_A17_df.loc[:, 'pred_Z'] - full_catalog_A17_df.loc[:, used_z_col]) /\\\n",
    "                                                  (1 + full_catalog_A17_df.loc[:, used_z_col]), decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    show_columns_A17 = ['RA_ICRS', 'DE_ICRS', 'Name', 'TYPE', 'band_num', 'class', 'radio_detect', 'Z', 'zsp', 'pred_Z', 'Delta_z_N']\n",
    "    display(full_catalog_A17_df.loc[:, show_columns_A17].sort_values(by='pred_Z', ascending=False).head(10))\n",
    "    display(full_catalog_A17_df.loc[:, show_columns_A17].sort_values(by=used_z_col, ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    sigma_mad_rAGN_A17            = sigma_mad(full_catalog_A17_df.loc[:, 'Z'],    full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_nmad_rAGN_A17           = sigma_nmad(full_catalog_A17_df.loc[:, 'Z'],   full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_z_rAGN_A17              = sigma_z(full_catalog_A17_df.loc[:, 'Z'],      full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    sigma_z_norm_rAGN_A17         = sigma_z_norm(full_catalog_A17_df.loc[:, 'Z'], full_catalog_A17_df.loc[:, 'pred_Z'])\n",
    "    out_frac_rAGN_A17             = outlier_frac(full_catalog_A17_df.loc[:, 'Z'], full_catalog_A17_df.loc[:, 'pred_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    print('Metrics for redshift prediction on radio AGN from Ananna et al., 2017')\n",
    "    print(f'Sample size,                        N = {np.sum(np.isfinite(full_catalog_A17_df.loc[:, \"zsp\"]) & np.isfinite(full_catalog_A17_df.loc[:, \"pred_Z\"])):,}')\n",
    "    print(f'Sigma MAD                       \\u03C3 MAD = {sigma_mad_rAGN_A17:.4f}')\n",
    "    print(f'Sigma NMAD,                    \\u03C3 NMAD = {sigma_nmad_rAGN_A17:.4f}')\n",
    "    print(f'Sigma z,                          \\u03C3 z = {sigma_z_rAGN_A17:.4f}')\n",
    "    print(f'Sigma z normalized,             \\u03C3 z N = {sigma_z_norm_rAGN_A17:.4f}')\n",
    "    print(f'Outlier fraction,                   \\u03B7 = {out_frac_rAGN_A17:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if compare_A17_flag:\n",
    "    fig             = plt.figure(figsize=(6,5))\n",
    "    ax1             = fig.add_subplot(111, projection='scatter_density', xscale='log', yscale='log')\n",
    "    plot_redshift_compare(full_catalog_A17_df.loc[:, used_z_col], full_catalog_A17_df.loc[:, 'pred_Z'],\\\n",
    "                          ax_pre=ax1, title=None, dpi=10, show_clb=True, log_stretch=False)\n",
    "    if save_plot_flag:\n",
    "        plt.savefig(f'plots/compare_redshift_{used_area}_Ananna_17.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
