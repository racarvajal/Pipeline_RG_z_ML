{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for High-z Radio Galaxies 12: Create lists (files) with radio AGN candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, three models will be applied consecutively in order to predict  \n",
    "the detection of Radio Galaxies (radio AGN) and their redshift.  \n",
    "\n",
    "In principle, this pipeline should be applied to data in Stripe 82. But  \n",
    "it can be used with any other suitable dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as mpe\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from astropy.visualization import LogStretch, PowerStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import sklearn.pipeline\n",
    "import colorcet as cc\n",
    "from pycaret import classification as pyc\n",
    "from pycaret import regression as pyr\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import mpl_scatter_density\n",
    "import global_variables as gv\n",
    "import global_functions as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpl.rcdefaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods to predict values using individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict AGN/Galaxy classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_AGN_gal(catalog_df, \n",
    "                    AGN_gal_model, \n",
    "                    cal_AGN_gal_model, \n",
    "                    threshold, \n",
    "                    cal_threshold, \n",
    "                    raw_score=True):\n",
    "    catalog_df = pyc.predict_model(AGN_gal_model, \n",
    "                                   data=catalog_df, \n",
    "                                   probability_threshold=threshold, \n",
    "                                   raw_score=raw_score, \n",
    "                                   round=10)\n",
    "    catalog_df = catalog_df.drop(columns=['Score_0'])\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_class', 'Score_1': 'Score_AGN'})\n",
    "    catalog_df.loc[:, 'Score_AGN'] = np.around(catalog_df.loc[:, 'Score_AGN'], decimals=8)\n",
    "    pred_probs = cal_AGN_gal_model.predict(catalog_df.loc[:, 'Score_AGN'])\n",
    "    cal_class  = np.array(pred_probs >= cal_threshold).astype(int)\n",
    "    catalog_df['Prob_AGN']       = pred_probs\n",
    "    catalog_df['pred_class_cal'] = cal_class\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict radio detection for AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_radio_det(catalog_df, \n",
    "                      radio_model, \n",
    "                      cal_radio_model, \n",
    "                      threshold, \n",
    "                      cal_threshold, \n",
    "                      raw_score=True):\n",
    "    catalog_df = pyc.predict_model(radio_model, \n",
    "                                   data=catalog_df, \n",
    "                                   probability_threshold=threshold, \n",
    "                                   raw_score=raw_score, \n",
    "                                   round=10)\n",
    "    catalog_df = catalog_df.drop(columns=['Score_0'])\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_radio', 'Score_1': 'Score_radio'})\n",
    "    catalog_df.loc[:, 'Score_radio'] = np.around(catalog_df.loc[:, 'Score_radio'], decimals=8)\n",
    "    pred_probs = cal_radio_model.predict(catalog_df.loc[:, 'Score_radio'])\n",
    "    cal_class  = np.array(pred_probs >= cal_threshold).astype(int)\n",
    "    catalog_df['Prob_radio']     = pred_probs\n",
    "    catalog_df['pred_radio_cal'] = cal_class\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict redshift for radio-detected AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_z(catalog_df, \n",
    "              redshift_model):\n",
    "    catalog_df = pyr.predict_model(redshift_model, \n",
    "                                   data=catalog_df, \n",
    "                                   round=10)\n",
    "    catalog_df = catalog_df.rename(columns={'Label': 'pred_Z'})\n",
    "    catalog_df.loc[:, 'pred_Z'] = np.around(catalog_df.loc[:, 'pred_Z'], decimals=4)\n",
    "    return catalog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot_flag      = False\n",
    "save_preds_flag     = False\n",
    "load_models_flag    = True\n",
    "predict_only_hi_z   = False\n",
    "use_zeroth_model    = False\n",
    "use_second_z_model  = False  # z >= 3.6 (with SMOGN), or, if needed, z >= 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_area           = 'HETDEX'  # can be 'S82', 'HETDEX', 'COSMOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name_dict      = {'S82': gv.file_S82, 'HETDEX': gv.file_HETDEX, 'COSMOS': gv.file_COSMOS}\n",
    "file_name           = file_name_dict[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feats_2_disc_S82    = ['objID', 'RA_MILLI', 'DEC_MILLI', 'W1mag', 'W2mag', 'num_imputed', 'radio_detect']\n",
    "feats_2_disc_HETDEX = ['objID', 'RA_MILLI', 'DEC_MILLI', 'W1mag', 'W2mag', 'num_imputed', 'radio_detect']\n",
    "feats_2_disc_COSMOS = ['objID', 'RA_MILLI', 'DEC_MILLI', 'W1mag', 'W2mag', 'num_imputed', 'radio_detect', ]\n",
    "\n",
    "feats_2_disc        = {'S82': feats_2_disc_S82, 'HETDEX': feats_2_disc_HETDEX, 'COSMOS': feats_2_disc_COSMOS}\n",
    "features_2_discard  = feats_2_disc[used_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df     = pd.read_hdf(gv.cat_path + file_name, key='df').drop(columns=features_2_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if used_area == 'S82':\n",
    "    full_catalog_df.loc[:, 'LOFAR_detect'] = full_catalog_df.loc[:, 'VLAS82_detect'].copy()\n",
    "    full_catalog_df = full_catalog_df.drop(columns=['VLAS82_detect'])\n",
    "if used_area == 'COSMOS':\n",
    "    full_catalog_df.loc[:, 'LOFAR_detect'] = full_catalog_df.loc[:, 'COSMOSVLA3_detect'].copy()\n",
    "    full_catalog_df = full_catalog_df.drop(columns=['COSMOSVLA3_detect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features with class and combined redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "full_catalog_df['class']            = full_catalog_df.loc[:, 'is_AGN'].copy()\n",
    "filter_non_confirmed                = np.array(full_catalog_df.loc[:, 'is_AGN'] == 1) | np.array(full_catalog_df.loc[:, 'is_gal'] == 1)\n",
    "full_catalog_df.loc[~filter_non_confirmed, 'class'] = np.nan\n",
    "idx_non_Z                           = full_catalog_df.loc[:, 'Z'].where(full_catalog_df.loc[:, 'Z'] > 0).isna()\n",
    "full_catalog_df.loc[idx_non_Z, 'Z'] = full_catalog_df.loc[:, 'Z'].mask(idx_non_Z, full_catalog_df.loc[idx_non_Z, 'zsp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column for detection as Radio AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['radio_AGN']      = (np.array(full_catalog_df.loc[:, 'is_AGN'] == 1) &\\\n",
    "                                     np.array(full_catalog_df.loc[:, 'LOFAR_detect'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard minor features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df                     = full_catalog_df.drop(columns=['is_AGN', 'is_SDSS_QSO', 'is_SDSS_gal', 'is_gal', 'zsp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we want to predict, only use sources that have not previous spectroscopic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The used data set (in HETDEX) has 15,136,878 sources.\n",
      "And 118,734 have previous spectroscopic classification.\n"
     ]
    }
   ],
   "source": [
    "print(f'The used data set (in {used_area}) has {len(full_catalog_df):,} sources.')\n",
    "print(f'And {np.sum(filter_non_confirmed):,} have previous spectroscopic classification.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df                     = full_catalog_df.loc[~filter_non_confirmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This pipeline will predict properties for 15,136,878 sources in HETDEX.\n"
     ]
    }
   ],
   "source": [
    "print(f'This pipeline will predict properties for {len(full_catalog_df):,} sources in {used_area}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "if load_models_flag:\n",
    "    if use_zeroth_model:\n",
    "        star_clf          = pyc.load_model(gv.models_path + gv.star_model)  # star/no-star model\n",
    "        cal_star_clf      = load(gv.models_path + gv.cal_str_model)  # calibrated model\n",
    "    AGN_gal_clf           = pyc.load_model(gv.models_path + gv.AGN_gal_model)  #\n",
    "    cal_AGN_gal_clf       = load(gv.models_path + gv.cal_AGN_gal_model)  # calibrated model\n",
    "    radio_det_AGN_clf     = pyc.load_model(gv.models_path + gv.radio_model)  # without predicted AGN\n",
    "    cal_radio_det_AGN_clf = load(gv.models_path + gv.cal_radio_model)  # calibrated model\n",
    "    redshift_reg_rAGN     = pyr.load_model(gv.models_path + gv.full_z_model)  # to use on full sample\n",
    "    if use_second_z_model:\n",
    "        redshift_reg_2    = pyr.load_model(gv.models_path + gv.high_z_model)  # sources with predicted z >= 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_catalog_df \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_AGN_gal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_catalog_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mAGN_gal_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcal_AGN_gal_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mgv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAGN_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mgv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_AGN_thresh\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mpredict_AGN_gal\u001b[0;34m(catalog_df, AGN_gal_model, cal_AGN_gal_model, threshold, cal_threshold, raw_score)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_AGN_gal\u001b[39m(catalog_df, \n\u001b[1;32m      2\u001b[0m                     AGN_gal_model, \n\u001b[1;32m      3\u001b[0m                     cal_AGN_gal_model, \n\u001b[1;32m      4\u001b[0m                     threshold, \n\u001b[1;32m      5\u001b[0m                     cal_threshold, \n\u001b[1;32m      6\u001b[0m                     raw_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 7\u001b[0m     catalog_df \u001b[38;5;241m=\u001b[39m \u001b[43mpyc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAGN_gal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatalog_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     catalog_df \u001b[38;5;241m=\u001b[39m catalog_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore_0\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m     catalog_df \u001b[38;5;241m=\u001b[39m catalog_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore_AGN\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pycaret/classification.py:2126\u001b[0m, in \u001b[0;36mpredict_model\u001b[0;34m(estimator, data, probability_threshold, encoded_labels, raw_score, drift_report, round, verbose, drift_kwargs)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_model\u001b[39m(\n\u001b[1;32m   2048\u001b[0m     estimator,\n\u001b[1;32m   2049\u001b[0m     data: Optional[pd\u001b[38;5;241m.\u001b[39mDataFrame] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     drift_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2057\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;124;03m    This function predicts ``Label`` and ``Score`` (probability of predicted\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;124;03m    class) using a trained model. When ``data`` is None, it predicts label and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2123\u001b[0m \n\u001b[1;32m   2124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpycaret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoded_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrift_report\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrift_report\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mml_usecase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMLUsecase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASSIFICATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrift_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrift_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pycaret/internal/tabular.py:9165\u001b[0m, in \u001b[0;36mpredict_model\u001b[0;34m(estimator, data, probability_threshold, encoded_labels, drift_report, raw_score, round, verbose, ml_usecase, display, drift_kwargs)\u001b[0m\n\u001b[1;32m   9163\u001b[0m     X_test_ \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_test_, y_test_, label], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   9164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 9165\u001b[0m     X_test_ \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9166\u001b[0m     X_test_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   9168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pandas/core/generic.py:6032\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5926\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   5928\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5929\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   5930\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6030\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   6031\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6032\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6033\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pandas/core/internals/managers.py:603\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m     new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/.miniforge3/envs/clone_test_pycaret/lib/python3.8/site-packages/pandas/core/internals/blocks.py:643\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    641\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 643\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(values, placement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_catalog_df = predict_AGN_gal(full_catalog_df, \n",
    "                                  AGN_gal_clf, \n",
    "                                  cal_AGN_gal_clf, \n",
    "                                  gv.AGN_thresh, \n",
    "                                  gv.cal_AGN_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = predict_radio_det(full_catalog_df, \n",
    "                                    radio_det_AGN_clf, \n",
    "                                    cal_radio_det_AGN_clf, \n",
    "                                    gv.radio_thresh, \n",
    "                                    gv.cal_radio_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df = full_catalog_df.rename(columns={'Score_radio': 'Score_radio_AGN', \n",
    "                                                            'pred_radio': 'pred_radio_AGN',\n",
    "                                                            'Prob_radio': 'Prob_radio_AGN', \n",
    "                                                            'pred_radio_cal': 'pred_radio_cal_AGN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "full_catalog_df = predict_z(full_catalog_df, redshift_reg_rAGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "full_catalog_df = full_catalog_df.rename(columns={'pred_Z': 'pred_Z_rAGN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.array(full_catalog_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df = pyc.predict_model(AGN_gal_clf, data=full_catalog_df, probability_threshold=gv.AGN_thresh, raw_score=True, round=10)\n",
    "# full_catalog_df = full_catalog_df.drop(columns=['Score_0'])\n",
    "# full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_class', 'Score_1': 'Score_AGN'})\n",
    "# full_catalog_df['Score_AGN'] = np.around(full_catalog_df.loc[:, 'Score_AGN'], decimals=7)\n",
    "# pred_probs_AGN  = cal_AGN_gal_clf.predict(full_catalog_df.loc[:, 'Score_AGN'])\n",
    "# full_catalog_df['Prob_AGN'] = pred_probs_AGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df = pyc.predict_model(radio_det_clf, data=full_catalog_df, probability_threshold=gv.radio_thresh, raw_score=True, round=10)\n",
    "# full_catalog_df = full_catalog_df.drop(columns=['Score_0'])\n",
    "# full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_radio', 'Score_1': 'Score_radio'})\n",
    "# full_catalog_df['Score_radio'] = np.around(full_catalog_df.loc[:, 'Score_radio'], decimals=7)\n",
    "# pred_probs_rad  = cal_radio_det_clf.predict(full_catalog_df.loc[:, 'Score_radio'])\n",
    "# full_catalog_df['Prob_radio'] = pred_probs_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df = pyr.predict_model(redshift_reg, data=full_catalog_df, round=8)\n",
    "# full_catalog_df = full_catalog_df.rename(columns={'Label': 'pred_Z'})\n",
    "# full_catalog_df['pred_Z'] = np.around(full_catalog_df.loc[:, 'pred_Z'], decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redshift_tol    = 0.0\n",
    "# if use_second_z_model:\n",
    "#     full_catalog_df = pyr.predict_model(redshift_reg_2, data=full_catalog_df, round=6)\n",
    "#     filter_pred_z   = full_catalog_df.loc[:, 'pred_Z'] >= (gv.high_z_limit + redshift_tol)\n",
    "#     full_catalog_df.loc[:, 'pred_Z'] = full_catalog_df.loc[:, 'pred_Z'].mask(filter_pred_z, full_catalog_df.loc[filter_pred_z, 'Label'])\n",
    "#     full_catalog_df = full_catalog_df.drop(columns=['Label'])\n",
    "#     full_catalog_df.loc[:, 'pred_Z'] = np.around(full_catalog_df.loc[:, 'pred_Z'], decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df['pred_prob_class']    = (full_catalog_df.loc[:, 'Prob_AGN']   >= gv.cal_AGN_thresh).astype(int)\n",
    "# full_catalog_df['pred_prob_radio']    = (full_catalog_df.loc[:, 'Prob_radio'] >= gv.cal_radio_thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df['pred_radio_AGN']     = (np.array(full_catalog_df.loc[:, 'pred_class'] == 1) & np.array(full_catalog_df.loc[:, 'pred_radio_AGN'] == 1)).astype(int)\n",
    "full_catalog_df['Score_rAGN']         = full_catalog_df.loc[:, 'Score_AGN'] * full_catalog_df.loc[:, 'Score_radio_AGN']\n",
    "full_catalog_df['pred_prob_rAGN']     = (np.array(full_catalog_df.loc[:, 'pred_class_cal'] == 1) & np.array(full_catalog_df.loc[:, 'pred_radio_cal_AGN'] == 1)).astype(int)\n",
    "full_catalog_df['Prob_rAGN']          = full_catalog_df.loc[:, 'Prob_AGN'] * full_catalog_df.loc[:, 'Prob_radio_AGN']\n",
    "\n",
    "# rad_score_scaler                      = MinMaxScaler()\n",
    "# full_catalog_df['scaled_score_radio'] = rad_score_scaler.fit_transform(full_catalog_df.loc[:, 'Score_radio'].values.reshape(-1, 1))\n",
    "# full_catalog_df['scaled_score_rAGN']  = full_catalog_df.loc[:, 'Score_AGN'] * full_catalog_df.loc[:, 'scaled_score_radio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df.loc[:, ['class', 'pred_class_cal', 'LOFAR_detect', 'pred_radio_cal_AGN', 'Z', 'pred_Z_rAGN']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain intermediate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_radio_AGN_t      = np.array(full_catalog_df.loc[:, 'class'] == 1) & np.array(full_catalog_df.loc[:, 'LOFAR_detect'] == 1)\n",
    "filter_gal_AGN_t        = np.array(full_catalog_df.loc[:, 'class'] == 0) | np.array(full_catalog_df.loc[:, 'class'] == 1)\n",
    "total_size              = len(full_catalog_df)\n",
    "filter_AGN_t            = np.array(full_catalog_df.loc[:, 'class'] == 1)\n",
    "num_AGN_t               = np.sum(filter_AGN_t)\n",
    "num_gal_t               = np.sum(np.array(full_catalog_df.loc[:, 'class'] == 0))\n",
    "num_radio_t             = np.sum(np.array(full_catalog_df.loc[:, 'LOFAR_detect'] == 1))\n",
    "num_radio_AGN_t         = np.sum(filter_radio_AGN_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_radio_AGN_p      = np.array(full_catalog_df.loc[:, 'Score_AGN']          >= threshold_AGN) &\\\n",
    "#                             np.array(full_catalog_df.loc[:, 'Score_radio']      >= threshold_radio)\n",
    "filter_radio_AGN_p      = np.array(full_catalog_df.loc[:, 'pred_class_cal']      == 1) &\\\n",
    "                            np.array(full_catalog_df.loc[:, 'pred_radio_cal_AGN']    == 1)\n",
    "filt_hiz_rAGN_p         = filter_radio_AGN_p * np.array(full_catalog_df.loc[:, 'pred_Z_rAGN'] >= gv.high_z_limit)\n",
    "filter_AGN_p            = np.array(full_catalog_df.loc[:, 'pred_class_cal']      == 1)\n",
    "filter_radio_p          = np.array(full_catalog_df.loc[:, 'pred_radio_cal_AGN']      == 1)\n",
    "num_AGN_p               = np.sum(filter_AGN_p)\n",
    "num_gal_p               = np.sum(np.array(full_catalog_df.loc[:, 'pred_class_cal'] == 0))\n",
    "num_radio_p             = np.sum(filter_radio_p)\n",
    "num_radio_AGN_p         = np.sum(filter_radio_AGN_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select sources predicted to be Radio AGN (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_df         = full_catalog_df.loc[filter_radio_AGN_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add individual metrics for redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_catalog_df['Delta_z_N'] = np.around((full_catalog_df.loc[:, 'pred_Z_rAGN'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)\n",
    "\n",
    "full_catalog_df['sigma_NMAD'] = np.around(1.48 * np.abs(full_catalog_df.loc[:, 'pred_Z_rAGN'] - full_catalog_df.loc[:, 'Z']) /\\\n",
    "                            (1 + full_catalog_df.loc[:, 'Z']), decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_0_t   = f'Out of {total_size:,} initial sources in {used_area},\\n'\n",
    "str_1_t   = f'{num_gal_t:,} are confirmed to be galaxies. On the other side,\\n'\n",
    "str_2_t   = f'{num_AGN_t:,} are confirmed to be AGN. And, from the AGN,\\n'\n",
    "str_3_t   = f'{num_radio_AGN_t:,} are detected in radio.'\n",
    "\n",
    "str_0_p   = f'Out of {num_radio_AGN_t:,} initial radio-detected AGN in {used_area},\\n'\n",
    "str_1_p   = f'{num_gal_p:,} are predicted to be galaxies. On the other side,\\n'\n",
    "str_2_p   = f'{num_AGN_p:,} are predicted to be AGN. And, from the predicted AGN,\\n'\n",
    "str_3_p   = f'{num_radio_AGN_p:,} are predicted to be detected in radio.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('-' * 60)\n",
    "print(str_0_t + str_1_t + str_2_t + str_3_t)\n",
    "print('-' * 60)\n",
    "print(str_0_p + str_1_p + str_2_p + str_3_p)\n",
    "print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_4_table = show_columns = ['Name', 'RA_ICRS', 'DE_ICRS', 'TYPE', 'band_num', 'class', 'pred_class',\n",
    "                               'pred_class_cal', 'Score_AGN', 'Prob_AGN', 'LOFAR_detect', 'pred_radio_AGN',\n",
    "                               'pred_radio_cal_AGN', 'Score_radio_AGN', 'Prob_radio_AGN', 'radio_AGN', 'pred_radio_AGN',\n",
    "                               'pred_prob_rAGN', 'Score_rAGN', 'Prob_rAGN', 'Z', 'pred_Z_rAGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_preds_flag:\n",
    "    if used_area == 'S82':\n",
    "        cols_2_save_preds = ['RA_ICRS', 'DE_ICRS', 'Name', 'band_num', 'class', 'Fint_VLAS82', \n",
    "                             'Fint_VLAS82_non_imp', 'W1mproPM', 'W2mproPM', 'gmag', 'rmag', \n",
    "                             'imag', 'zmag', 'ymag', 'W3mag', 'W4mag', 'Jmag', 'Hmag', 'Kmag', \n",
    "                             'Score_AGN', 'Prob_AGN', 'LOFAR_detect', 'Score_radio_AGN', \n",
    "                             'Prob_radio_AGN', 'radio_AGN', 'Score_rAGN', 'Prob_rAGN', 'Z', \n",
    "                             'pred_Z_rAGN']  # 'rms_VLAS82'\n",
    "    if used_area == 'HETDEX':\n",
    "        cols_2_save_preds = ['RA_ICRS', 'DE_ICRS', 'Name', 'band_num', 'class', 'Sint_LOFAR', \n",
    "                             'Sint_LOFAR_non_imp', 'W1mproPM', 'W2mproPM', 'gmag', 'rmag', \n",
    "                             'imag', 'zmag', 'ymag', 'W3mag', 'W4mag', 'Jmag', 'Hmag', 'Kmag', \n",
    "                             'Score_AGN', 'Prob_AGN', 'LOFAR_detect', 'Score_radio_AGN', \n",
    "                             'Prob_radio_AGN', 'radio_AGN', 'Score_rAGN', 'Prob_rAGN', 'Z', 'pred_Z_rAGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_4_export_S82    = ['Fint_VLAS82']\n",
    "cols_4_export_HETDEX = ['Sint_LOFAR']\n",
    "cols_4_export_COSMOS = ['Flux_COSMOSVLA3']\n",
    "\n",
    "cols_4_exp_all       = {'S82': cols_4_export_S82, 'HETDEX': cols_4_export_HETDEX, 'COSMOS': cols_4_export_COSMOS}\n",
    "\n",
    "cols_photo           = ['W1mproPM', 'W2mproPM', 'gmag', 'rmag', 'imag', 'zmag', \n",
    "                        'ymag', 'Jmag', 'Hmag', 'Kmag', 'W3mag', 'W4mag']\n",
    "\n",
    "cols_4_export        = cols_4_table + cols_4_exp_all[used_area] + cols_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_new_rAGN = full_catalog_df.loc[:, 'radio_AGN'] == 0\n",
    "if predict_only_hi_z:\n",
    "    filter_high_z   = full_catalog_df.loc[:, 'pred_Z_rAGN']    >= gv.high_z_limit\n",
    "elif not predict_only_hi_z:\n",
    "    filter_high_z   = np.ones_like(full_catalog_df.loc[:, 'pred_Z_rAGN']).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_catalog_df.loc[:, 'TYPE'] = full_catalog_df.loc[:, 'TYPE'].mask(full_catalog_df.loc[:, 'TYPE'] == '    ', 'CCCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_catalog_df.loc[filter_high_z, cols_4_export].sort_values(by=['pred_Z_rAGN'], ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_preds_flag:\n",
    "    saving_data_pred       = full_catalog_df.loc[:, cols_2_save_preds]\n",
    "    # full_catalog_df.loc[filter_high_z, cols_4_export].sort_values(by=['pred_Z_rAGN'],\n",
    "    #  ascending=False).to_csv(gv.preds_path + f'predicted_rAGN_{used_area}.csv', index_label='ID')\n",
    "    file_name_csv  = gv.preds_path + f'predicted_rAGN_{used_area}.csv'\n",
    "    file_name_prqt = gv.preds_path + f'predicted_rAGN_{used_area}.parquet'\n",
    "    saving_data_pred.to_csv(file_name_csv, index_label='ID')\n",
    "    # saving_data_pred['ID'] = saving_data_pred.index\n",
    "    saving_data_pred.to_parquet(file_name_prqt, index=True, engine='fastparquet')\n",
    "    print(f'Data from {used_area} saved in files {file_name_csv} and {file_name_prqt}.')\n",
    "    print(f'Each file contains {len(saving_data_pred)} entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_flag:\n",
    "    cols_AGN   = ['g_r', 'r_i', 'r_J', 'i_z', 'i_y', \n",
    "                  'z_y', 'z_W2', 'y_J', 'y_W1', 'y_W2', 'J_H', 'H_K', \n",
    "                  'H_W3', 'W1_W2', 'W1_W3', 'W3_W4']  # Only colours (no 'band_num', 'W4mag')\n",
    "    cols_radio = ['g_r', 'g_i', 'r_i', 'r_z', 'i_z', \n",
    "                  'z_y', 'z_W1', 'y_J', 'y_W1', 'J_H', 'H_K', 'K_W3', \n",
    "                  'K_W4', 'W1_W2', 'W2_W3']  # Only colours (no 'band_num', 'W4mag')\n",
    "    cols_z     = ['g_r', 'g_W3', 'r_i', 'r_z', 'i_z', \n",
    "                  'i_y', 'z_y', 'y_J', 'y_W1', 'J_H', 'H_K', 'K_W3', \n",
    "                  'K_W4', 'W1_W2', 'W2_W3']  # Only colours (no 'band_num', 'W4mag')\n",
    "    \n",
    "    cols_cols = list(np.unique(cols_AGN + cols_radio + cols_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_flag:\n",
    "    \n",
    "    add_columns  = ['band_num', 'class', 'pred_class_cal', 'Score_AGN', 'Prob_AGN', \n",
    "                    'LOFAR_detect', 'pred_radio_cal_AGN', 'Score_radio_AGN', 'Prob_radio_AGN', \n",
    "                    'radio_AGN', 'pred_prob_rAGN', 'Score_rAGN', 'Prob_rAGN', 'Z', 'pred_Z_rAGN']\n",
    "    used_colours = cols_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp_flag:\n",
    "    saving_data = full_catalog_df.loc[:, add_columns + cols_photo + used_colours]\n",
    "    saving_data['ID'] = saving_data.index\n",
    "    file_name         = gv.preds_path + f'{used_area}_for_prediction.h5'\n",
    "    file_name_pqt     = gv.preds_path + f'{used_area}_for_prediction.parquet'\n",
    "    saving_data.to_hdf(file_name, key='df')\n",
    "    saving_data.to_parquet(file_name_pqt, index=True, engine='fastparquet')\n",
    "    print(f'Data from {used_area} saved in files {file_name} and {file_name_pqt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_full_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(full_catalog_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_full_flag:\n",
    "    if used_area == 'S82':\n",
    "        cols_2_save = ['RA_ICRS', 'DE_ICRS', 'Name', 'TYPE', 'Z', 'band_num', 'Fint_VLAS82', \n",
    "                       'Fint_VLAS82_AB', 'Fint_VLAS82_non_imp', 'is_str', 'W1mproPM', \n",
    "                       'W2mproPM', 'gmag', 'rmag', 'imag', 'zmag', 'ymag', 'W3mag', 'W4mag', 'Jmag', \n",
    "                       'Hmag', 'Kmag', 'g_r', 'g_i', 'g_z', 'g_y', 'g_J', 'g_H', 'g_K', 'g_W1', \n",
    "                       'g_W2', 'g_W3', 'g_W4', 'r_i', 'r_z', 'r_y', 'r_J', 'r_H', 'r_K', 'r_W1', \n",
    "                       'r_W2', 'r_W3', 'r_W4', 'i_z', 'i_y', 'i_J', 'i_H', 'i_K', 'i_W1', 'i_W2', \n",
    "                       'i_W3', 'i_W4', 'z_y', 'z_J', 'z_H', 'z_K', 'z_W1', 'z_W2', 'z_W3', 'z_W4', \n",
    "                       'y_J', 'y_H', 'y_K', 'y_W1', 'y_W2', 'y_W3', 'y_W4', 'J_H', 'J_K', 'J_W1', \n",
    "                       'J_W2', 'J_W3', 'J_W4', 'H_K', 'H_W1', 'H_W2', 'H_W3', 'H_W4', 'K_W1', \n",
    "                       'K_W2', 'K_W3', 'K_W4', 'W1_W2', 'W1_W3', 'W1_W4', 'W2_W3', 'W2_W4', 'W3_W4', \n",
    "                       'LOFAR_detect', 'class', 'radio_AGN', 'Prob_AGN', 'Prob_radio_AGN', \n",
    "                       'pred_Z_rAGN', 'pred_class_cal', 'pred_radio_cal_AGN', 'pred_prob_rAGN', 'Prob_rAGN']  # 'rms_VLAS82'\n",
    "    if used_area == 'HETDEX':\n",
    "        cols_2_save = ['RA_ICRS', 'DE_ICRS', 'Name', 'TYPE', 'Z', 'band_num', 'Sint_LOFAR', \n",
    "                       'Sint_LOFAR_AB', 'Sint_LOFAR_non_imp', 'rms_LOFAR', 'Speak_LOFAR', \n",
    "                       'Speak_LOFAR_non_imp', 'is_str', 'W1mproPM', 'W2mproPM', 'gmag', 'rmag', \n",
    "                       'imag', 'zmag', 'ymag', 'W3mag', 'W4mag', 'Jmag', 'Hmag', 'Kmag', 'g_r', \n",
    "                       'g_i', 'g_z', 'g_y', 'g_J', 'g_H', 'g_K', 'g_W1', 'g_W2', 'g_W3', 'g_W4', \n",
    "                       'r_i', 'r_z', 'r_y', 'r_J', 'r_H', 'r_K', 'r_W1', 'r_W2', 'r_W3', 'r_W4', \n",
    "                       'i_z','i_y', 'i_J', 'i_H', 'i_K', 'i_W1', 'i_W2', 'i_W3', 'i_W4', 'z_y', \n",
    "                       'z_J', 'z_H', 'z_K', 'z_W1', 'z_W2', 'z_W3', 'z_W4', 'y_J', 'y_H', 'y_K', \n",
    "                       'y_W1', 'y_W2', 'y_W3', 'y_W4', 'J_H', 'J_K', 'J_W1', 'J_W2', 'J_W3', 'J_W4', \n",
    "                       'H_K', 'H_W1', 'H_W2', 'H_W3', 'H_W4', 'K_W1', 'K_W2', 'K_W3', 'K_W4', \n",
    "                       'W1_W2', 'W1_W3', 'W1_W4', 'W2_W3', 'W2_W4', 'W3_W4', 'LOFAR_detect', \n",
    "                       'class', 'radio_AGN', 'Prob_AGN', 'Prob_radio_AGN', 'pred_Z_rAGN', \n",
    "                       'pred_class_cal', 'pred_radio_cal_AGN', 'pred_prob_rAGN', 'Prob_rAGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_full_flag:\n",
    "    saving_data_full       = full_catalog_df.loc[:, cols_2_save]\n",
    "    saving_data_full['ID'] = saving_data_full.index\n",
    "    try:\n",
    "        saving_data_full.to_hdf(gv.preds_path + f'{used_area}_full_prediction.h5', key='df')\n",
    "        print(f'File {gv.preds_path}{used_area}_full_prediction.h5 saved')\n",
    "    except:\n",
    "        print(f'File {gv.preds_path}{used_area}_full_prediction.h5 was not saved')\n",
    "    try:\n",
    "        saving_data_full.to_parquet(gv.preds_path + f'{used_area}_full_prediction.parquet', index=True, engine='fastparquet')\n",
    "        print(f'File {gv.preds_path}{used_area}_full_prediction.parquet saved')\n",
    "    except:\n",
    "        print(f'File {gv.preds_path}{used_area}_full_prediction.parquet was not saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d7c94ac87c57432169d0bc24ce250f6f2e77b44a3b95192eb5ace62cff26777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
